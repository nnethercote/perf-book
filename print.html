<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Rust Performance Book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Rust Performance Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/nnethercote/perf-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-rust-performance-book"><a class="header" href="#the-rust-performance-book"><span style="font-size: 150%">The Rust Performance Book</span></a></h1>
<p><strong><span style="font-size: 130%">First published in November 2020</span></strong></p>
<p><strong><span style="font-size: 130%">Written by Nicholas Nethercote and others</span></strong></p>
<p><a href="https://github.com/nnethercote/perf-book">Source code</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Performance is important for many Rust programs.</p>
<p>This book contains techniques that can improve the performance-related
characteristics of Rust programs, such as runtime speed, memory usage, and
binary size. The <a href="compile-times.html">Compile Times</a> section also contains techniques that will
improve the compile times of Rust programs. Some techniques only require
changing build configurations, but many require changing code.</p>
<p>Some techniques are entirely Rust-specific, and some involve ideas that can be
applied (often with modifications) to programs written in other languages. The
<a href="general-tips.html">General Tips</a> section also includes some general principles that apply to any
programming language. Nonetheless, this book is mostly about the performance of
Rust programs and is no substitute for a general purpose guide to profiling and
optimization.</p>
<p>This book also focuses on techniques that are practical and proven: many are
accompanied by links to pull requests or other resources that show how the
technique was used on a real-world Rust program. It reflects the primary
author’s background, being somewhat biased towards compiler development and
away from other areas such as scientific computing.</p>
<p>This book is deliberately terse, favouring breadth over depth, so that it is
quick to read. It links to external sources that provide more depth when
appropriate.</p>
<p>This book is aimed at intermediate and advanced Rust users. Beginner Rust users
have more than enough to learn and these techniques are likely to be an
unhelpful distraction to them.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h1>
<p>Benchmarking typically involves comparing the performance of two or more
programs that do the same thing. Sometimes this might involve comparing two or
more different programs, e.g. Firefox vs Safari vs Chrome. Sometimes it
involves comparing two different versions of the same program. This latter case
lets us reliably answer the question “did this change speed things up?”</p>
<p>Benchmarking is a complex topic and a thorough coverage is beyond the scope of
this book, but here are the basics.</p>
<p>First, you need workloads to measure. Ideally, you would have a variety of
workloads that represent realistic usage of your program. Workloads using
real-world inputs are best, but <a href="https://stackoverflow.com/questions/2842695/what-is-microbenchmarking">microbenchmarks</a> and <a href="https://en.wikipedia.org/wiki/Stress_testing_(software)">stress tests</a> can be
useful in moderation.</p>
<p>Second, you need a way to run the workloads, which will also dictate the
metrics used.</p>
<ul>
<li>Rust’s built-in <a href="https://doc.rust-lang.org/nightly/unstable-book/library-features/test.html">benchmark tests</a> are a simple starting point, but they use
unstable features and therefore only work on nightly Rust.</li>
<li><a href="https://github.com/bheisler/criterion.rs">Criterion</a> and <a href="https://github.com/nvzqz/divan">Divan</a> are more sophisticated alternatives.</li>
<li><a href="https://github.com/sharkdp/hyperfine">Hyperfine</a> is an excellent general-purpose benchmarking tool.</li>
<li><a href="https://github.com/bencherdev/bencher">Bencher</a> can do continuous benchmarking on CI, including GitHub CI.</li>
<li>Custom benchmarking harnesses are also possible. For example, <a href="https://github.com/rust-lang/rustc-perf/">rustc-perf</a> is
the harness used to benchmark the Rust compiler.</li>
</ul>
<p>When it comes to metrics, there are many choices, and the right one(s) will
depend on the nature of the program being benchmarked. For example, metrics
that make sense for a batch program might not make sense for an interactive
program. Wall-time is an obvious choice in many cases because it corresponds to
what users perceive. However, it can suffer from high variance. In particular,
tiny changes in memory layout can cause significant but ephemeral performance
fluctuations. Therefore, other metrics with lower variance (such as cycles or
instruction counts) may be a reasonable alternative.</p>
<p>Summarizing measurements from multiple workloads is also a challenge, and there
are a variety of ways to do it, with no single method being obviously best.</p>
<p>Good benchmarking is hard. Having said that, do not stress too much about
having a perfect benchmarking setup, particularly when you start optimizing a
program. Mediocre benchmarking is far better than no benchmarking. Keep an open
mind about what you are measuring, and over time you can make benchmarking
improvements as you learn about the performance characteristics of your
program.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="build-configuration"><a class="header" href="#build-configuration">Build Configuration</a></h1>
<p>You can drastically change the performance of a Rust program without changing
its code, just by changing its build configuration. There are many possible
build configurations for each Rust program. The one chosen will affect several
characteristics of the compiled code, such as compile times, runtime speed,
memory use, binary size, debuggability, profilability, and which architectures
your compiled program will run on.</p>
<p>Most configuration choices will improve one or more characteristics while
worsening one or more others. For example, a common trade-off is to accept
worse compile times in exchange for higher runtime speeds. The right choice
for your program depends on your needs and the specifics of your program, and
performance-related choices (which is most of them) should be validated with
benchmarking.</p>
<p>It is worth reading this chapter carefully to understand all the build
configuration choices. However, for the impatient or forgetful,
<a href="https://github.com/Kobzol/cargo-wizard"><code>cargo-wizard</code></a> encapsulates this information and can help you choose an
appropriate build configuration.</p>
<p>Note that Cargo only looks at the profile settings in the <code>Cargo.toml</code> file at
the root of the workspace. Profile settings defined in dependencies are
ignored. Therefore, these options are mostly relevant for binary crates, not
library crates.</p>
<h2 id="release-builds"><a class="header" href="#release-builds">Release Builds</a></h2>
<p>The single most important build configuration choice is simple but <a href="https://users.rust-lang.org/t/why-my-rust-program-is-so-slow/47764/5">easy to
overlook</a>: make sure you are using a <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#release">release build</a> rather than a <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#dev">dev build</a>
when you want high performance. This is usually done by specifying the
<code>--release</code> flag to Cargo.</p>
<p>Dev builds are the default. They are good for debugging, but are not optimized.
They are produced if you run <code>cargo build</code> or <code>cargo run</code>. (Alternatively,
running <code>rustc</code> without additional options also produces an unoptimized build.)</p>
<p>Consider the following final line of output from a <code>cargo build</code> run.</p>
<pre><code class="language-text">Finished dev [unoptimized + debuginfo] target(s) in 29.80s
</code></pre>
<p>This output indicates that a dev build has been produced. The compiled code
will be placed in the <code>target/debug/</code> directory. <code>cargo run</code> will run the dev
build.</p>
<p>In comparison, release builds are much more optimized, omit debug assertions
and integer overflow checks, and omit debug info. 10-100x speedups over dev
builds are common! They are produced if you run <code>cargo build --release</code> or
<code>cargo run --release</code>. (Alternatively, <code>rustc</code> has multiple options for
optimized builds, such as <code>-O</code> and <code>-C opt-level</code>.) This will typically take
longer than a dev build because of the additional optimizations.</p>
<p>Consider the following final line of output from a <code>cargo build --release</code> run.</p>
<pre><code class="language-text">Finished release [optimized] target(s) in 1m 01s
</code></pre>
<p>This output indicates that a release build has been produced. The compiled code
will be placed in the <code>target/release/</code> directory. <code>cargo run --release</code> will
run the release build.</p>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html">Cargo profile documentation</a> for more details about the differences
between dev builds (which use the <code>dev</code> profile) and release builds (which use
the <code>release</code> profile).</p>
<p>The default build configuration choices used in release builds provide a good
balance between the abovementioned characteristics such as compile times, runtime
speed, and binary size. But there are many possible adjustments, as the
following sections explain.</p>
<h2 id="maximizing-runtime-speed"><a class="header" href="#maximizing-runtime-speed">Maximizing Runtime Speed</a></h2>
<p>The following build configuration options are designed primarily to maximize
runtime speed. Some of them may also reduce binary size.</p>
<h3 id="codegen-units"><a class="header" href="#codegen-units">Codegen Units</a></h3>
<p>The Rust compiler splits crates into multiple <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#codegen-units">codegen units</a> to parallelize
(and thus speed up) compilation. However, this might cause it to miss some
potential optimizations. You may be able to improve runtime speed and reduce
binary size, at the cost of increased compile times, by setting the number of
units to one. Add these lines to the <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
codegen-units = 1
</code></pre>
<!-- Using `https` for this link triggers "potential security risk" warnings due
to a certificate problem. -->
<p><a href="http://likebike.com/posts/How_To_Write_Fast_Rust_Code.html#emit-asm"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/115554#issuecomment-1742192440"><strong>Example 2</strong></a>.</p>
<h3 id="link-time-optimization"><a class="header" href="#link-time-optimization">Link-time Optimization</a></h3>
<p><a href="https://doc.rust-lang.org/cargo/reference/profiles.html#lto">Link-time optimization</a> (LTO) is a whole-program optimization technique that
can improve runtime speed by 10-20% or more, and also reduce binary size, at
the cost of worse compile times. It comes in several forms.</p>
<p>The first form of LTO is <em>thin local LTO</em>, a lightweight form of LTO. By
default the compiler uses this for any build that involves a non-zero level of
optimization. This includes release builds. To explicitly request this level of
LTO, put these lines in the <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
lto = false
</code></pre>
<p>The second form of LTO is <em>thin LTO</em>, which is a little more aggressive, and
likely to improve runtime speed and reduce binary size while also increasing
compile times. Use <code>lto = "thin"</code> in <code>Cargo.toml</code> to enable it.</p>
<p>The third form of LTO is <em>fat LTO</em>, which is even more aggressive, and may
improve performance and reduce binary size further while increasing build
times again. Use <code>lto = "fat"</code> in <code>Cargo.toml</code> to enable it.</p>
<p>Finally, it is possible to fully disable LTO, which will likely worsen runtime
speed and increase binary size but reduce compile times. Use <code>lto = "off"</code> in
<code>Cargo.toml</code> for this. Note that this is different to the <code>lto = false</code> option,
which, as mentioned above, leaves thin local LTO enabled.</p>
<h3 id="alternative-allocators"><a class="header" href="#alternative-allocators">Alternative Allocators</a></h3>
<p>It is possible to replace the default (system) heap allocator used by a Rust
program with an alternative allocator. The exact effect will depend on the
individual program and the alternative allocator chosen, but large improvements
in runtime speed and large reductions in memory usage have been seen in
practice. The effect will also vary across platforms, because each platform’s
system allocator has its own strengths and weaknesses. The use of an
alternative allocator is also likely to increase binary size and compile times.</p>
<h4 id="jemalloc"><a class="header" href="#jemalloc">jemalloc</a></h4>
<p>One popular alternative allocator for Linux and Mac is <a href="https://github.com/jemalloc/jemalloc">jemalloc</a>, usable via
the <a href="https://crates.io/crates/tikv-jemallocator"><code>tikv-jemallocator</code></a> crate. To use it, add a dependency to your
<code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[dependencies]
tikv-jemallocator = "0.5"
</code></pre>
<p>Then add the following to your Rust code, e.g. at the top of <code>src/main.rs</code>:</p>
<pre><code class="language-rust ignore">#[global_allocator]
static GLOBAL: tikv_jemallocator::Jemalloc = tikv_jemallocator::Jemalloc;</code></pre>
<p>Furthermore, on Linux, jemalloc can be configured to use <a href="https://www.kernel.org/doc/html/next/admin-guide/mm/transhuge.html">transparent huge
pages</a> (THP). This can further speed up programs, possibly at the cost of
higher memory usage.</p>
<p>Do this by setting the <code>MALLOC_CONF</code> environment variable (or perhaps
<a href="https://github.com/tikv/jemallocator/issues/65"><code>_RJEM_MALLOC_CONF</code></a>) appropriately before building your program, for example:</p>
<pre><code class="language-bash">MALLOC_CONF="thp:always,metadata_thp:always" cargo build --release
</code></pre>
<p>The system running the compiled program also has to be configured to support
THP. See <a href="https://kobzol.github.io/rust/rustc/2023/10/21/make-rust-compiler-5percent-faster.html">this blog post</a> for more details.</p>
<h4 id="mimalloc"><a class="header" href="#mimalloc">mimalloc</a></h4>
<p>Another alternative allocator that works on many platforms is <a href="https://github.com/microsoft/mimalloc">mimalloc</a>,
usable via the <a href="https://crates.io/crates/mimalloc"><code>mimalloc</code></a> crate. To use it, add a dependency to your
<code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[dependencies]
mimalloc = "0.1"
</code></pre>
<p>Then add the following to your Rust code, e.g. at the top of <code>src/main.rs</code>:</p>
<pre><code class="language-rust ignore">#[global_allocator]
static GLOBAL: mimalloc::MiMalloc = mimalloc::MiMalloc;</code></pre>
<h3 id="cpu-specific-instructions"><a class="header" href="#cpu-specific-instructions">CPU Specific Instructions</a></h3>
<p>If you do not care about the compatibility of your binary on older (or other
types of) processors, you can tell the compiler to generate the newest (and
potentially fastest) instructions specific to a <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#target-cpu">certain CPU architecture</a>,
such as AVX SIMD instructions for x86-64 CPUs.</p>
<p>To request these instructions from the command line, use the <code>-C target-cpu=native</code> flag. For example:</p>
<pre><code class="language-bash">RUSTFLAGS="-C target-cpu=native" cargo build --release
</code></pre>
<p>Alternatively, to request these instructions from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for
one or more projects), add these lines:</p>
<pre><code class="language-toml">[build]
rustflags = ["-C", "target-cpu=native"]
</code></pre>
<p>This can improve runtime speed, especially if the compiler finds vectorization
opportunities in your code.</p>
<p>If you are unsure whether <code>-C target-cpu=native</code> is working optimally, compare
the output of <code>rustc --print cfg</code> and <code>rustc --print cfg -C target-cpu=native</code>
to see if the CPU features are being detected correctly in the latter case. If
not, you can use <code>-C target-feature</code> to target specific features.</p>
<h3 id="profile-guided-optimization"><a class="header" href="#profile-guided-optimization">Profile-guided Optimization</a></h3>
<p>Profile-guided optimization (PGO) is a compilation model where you compile
your program, run it on sample data while collecting profiling data, and then
use that profiling data to guide a second compilation of the program. This can
improve runtime speed by 10% or more.
<a href="https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/96978"><strong>Example 2</strong></a>.</p>
<p>It is an advanced technique that takes some effort to set up, but is worthwhile
in some cases. See the <a href="https://doc.rust-lang.org/rustc/profile-guided-optimization.html">rustc PGO documentation</a> for details. Also, the
<a href="https://github.com/Kobzol/cargo-pgo"><code>cargo-pgo</code></a> command makes it easier to use PGO (and <a href="https://github.com/llvm/llvm-project/tree/main/bolt">BOLT</a>, which is similar)
to optimize Rust binaries.</p>
<p>Unfortunately, PGO is not supported for binaries hosted on crates.io and
distributed via <code>cargo install</code>, which limits its usability.</p>
<h2 id="minimizing-binary-size"><a class="header" href="#minimizing-binary-size">Minimizing Binary Size</a></h2>
<p>The following build configuration options are designed primarily to minimize
binary size. Their effects on runtime speed vary.</p>
<h3 id="optimization-level"><a class="header" href="#optimization-level">Optimization Level</a></h3>
<p>You can request an <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#opt-level">optimization level</a> that aims to minimize binary size by
adding these lines to the <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
opt-level = "z"
</code></pre>
<p>This may also reduce runtime speed.</p>
<p>An alternative is <code>opt-level = "s"</code>, which targets minimal binary size a little
less aggressively. Compared to <code>opt-level = "z"</code>, it allows <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#inline-threshold">slightly more
inlining</a> and also the vectorization of loops.</p>
<h3 id="abort-on-panic"><a class="header" href="#abort-on-panic">Abort on <code>panic!</code></a></h3>
<p>If you do not need to unwind on panic, e.g. because your program doesn’t use
<a href="https://doc.rust-lang.org/std/panic/fn.catch_unwind.html"><code>catch_unwind</code></a>, you can tell the compiler to simply <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#panic">abort on panic</a>. On
panic, your program will still produce a backtrace.</p>
<p>This might reduce binary size and increase runtime speed slightly, and may even
reduce compile times slightly. Add these lines to the <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
panic = "abort"
</code></pre>
<h3 id="strip-debug-info-and-symbols"><a class="header" href="#strip-debug-info-and-symbols">Strip Debug Info and Symbols</a></h3>
<p>You can tell the compiler to <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#strip">strip</a> debug info and symbols from the compiled
binary. Add these lines to <code>Cargo.toml</code> to strip just debug info:</p>
<pre><code class="language-toml">[profile.release]
strip = "debuginfo"
</code></pre>
<p>Alternatively, use <code>strip = "symbols"</code> to strip both debug info and symbols.</p>
<p>Prior to Rust 1.77, the default behaviour was to do no stripping. <a href="https://blog.rust-lang.org/2024/03/21/Rust-1.77.0.html#enable-strip-in-release-profiles-by-default">As of Rust
1.77</a> the default behaviour is to strip debug info in release builds.</p>
<p>Stripping debug info can greatly reduce binary size. On Linux, the binary size
of a small Rust programs might shrink by 4x when debug info is stripped.
Stripping symbols can also reduce binary size, though generally not by as much.
<a href="https://github.com/nnethercote/counts/commit/53cab44cd09ff1aa80de70a6dbe1893ff8a41142"><strong>Example</strong></a>.
The exact effects are platform-dependent.</p>
<p>However, stripping makes your compiled program more difficult to debug and
profile. For example, if a stripped program panics, the backtrace produced may
contain less useful information than normal. The exact effects for the two
levels of stripping depend on the platform.</p>
<h3 id="other-ideas"><a class="header" href="#other-ideas">Other Ideas</a></h3>
<p>For more advanced binary size minimization techniques, consult the
comprehensive documentation in the excellent <a href="https://github.com/johnthagen/min-sized-rust"><code>min-sized-rust</code></a> repository.</p>
<h2 id="minimizing-compile-times"><a class="header" href="#minimizing-compile-times">Minimizing Compile Times</a></h2>
<p>The following build configuration options are designed primarily to minimize
compile times.</p>
<h3 id="linking"><a class="header" href="#linking">Linking</a></h3>
<p>A big part of compile time is actually linking time, particularly when
rebuilding a program after a small change. It is possible to select a faster
linker than the default one.</p>
<p>One option is <a href="https://lld.llvm.org/">lld</a>, which is available on Linux and Windows. To specify lld
from the command line, use the <code>-C link-arg=-fuse-ld=lld</code> flag. For example:</p>
<pre><code class="language-bash">RUSTFLAGS="-C link-arg=-fuse-ld=lld" cargo build --release
</code></pre>
<p>Alternatively, to specify lld from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for one or more
projects), add these lines:</p>
<pre><code class="language-toml">[build]
rustflags = ["-C", "link-arg=-fuse-ld=lld"]
</code></pre>
<p>lld is not fully supported for use with Rust, but it should work for most use
cases on Linux and Windows. There is a <a href="https://github.com/rust-lang/rust/issues/39915#issuecomment-618726211">GitHub Issue</a> tracking full support for
lld.</p>
<p>Another option is <a href="https://github.com/rui314/mold">mold</a>, which is currently available on Linux.
Simply substitute <code>mold</code> for <code>lld</code> in the instructions above. mold is often
faster than lld.
<a href="https://davidlattimore.github.io/posts/2024/02/04/speeding-up-the-rust-edit-build-run-cycle.html"><strong>Example</strong></a>.
It is also much newer and may not work in all cases.</p>
<p>Unlike the other options in this chapter, there are no trade-offs here!
Alternative linkers can be dramatically faster, without any downsides.</p>
<h3 id="experimental-parallel-front-end"><a class="header" href="#experimental-parallel-front-end">Experimental Parallel Front-end</a></h3>
<p>If you use nightly Rust, you can enable the experimental <a href="https://blog.rust-lang.org/2023/11/09/parallel-rustc.html">parallel front-end</a>.
It may reduce compile times at the cost of higher compile-time memory usage. It
won’t affect the quality of the generated code.</p>
<p>You can do that by adding <code>-Zthreads=N</code> to RUSTFLAGS, for example:</p>
<pre><code class="language-bash">RUSTFLAGS="-Zthreads=8" cargo build --release
</code></pre>
<p>Alternatively, to enable the parallel front-end from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for
one or more projects), add these lines:</p>
<pre><code class="language-toml">[build]
rustflags = ["-Z", "threads=8"]
</code></pre>
<p>Values other than <code>8</code> are possible, but that is the number that tends to give
the best results.</p>
<p>In the best cases, the experimental parallel front-end reduces compile times by
up to 50%. But the effects vary widely and depend on the characteristics of the
code and its build configuration, and for some programs there is no compile
time improvement.</p>
<h3 id="cranelift-codegen-back-end"><a class="header" href="#cranelift-codegen-back-end">Cranelift Codegen Back-end</a></h3>
<p>If you use nightly Rust you can enable the Cranelift codegen back-end on <a href="https://github.com/rust-lang/rustc_codegen_cranelift#platform-support">some
platforms</a>. It may reduce compile times at the cost of lower quality generated
code, and therefore is recommended for dev builds rather than release builds.</p>
<p>First, install the back-end with this <code>rustup</code> command:</p>
<pre><code class="language-bash">rustup component add rustc-codegen-cranelift-preview --toolchain nightly
</code></pre>
<p>To select Cranelift from the command line, use the
<code>-Zcodegen-backend=cranelift</code> flag. For example:</p>
<pre><code class="language-bash">RUSTFLAGS="-Zcodegen-backend=cranelift" cargo +nightly build
</code></pre>
<p>Alternatively, to specify Cranelift from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for one or
more projects), add these lines:</p>
<pre><code class="language-toml">[unstable]
codegen-backend = true

[profile.dev]
codegen-backend = "cranelift"
</code></pre>
<p>For more information, see the <a href="https://github.com/rust-lang/rustc_codegen_cranelift">Cranelift documentation</a>.</p>
<h2 id="custom-profiles"><a class="header" href="#custom-profiles">Custom profiles</a></h2>
<p>In addition to the <code>dev</code> and <code>release</code> profiles, Cargo supports <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#custom-profiles">custom
profiles</a>. It might be useful, for example, to create a custom profile halfway
between <code>dev</code> and <code>release</code> if you find the runtime speed of dev builds
insufficient and the compile times of release builds too slow for everyday
development.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>There are many choices to be made when it comes to build configurations. The
following points summarize the above information into some recommendations.</p>
<ul>
<li>If you want to maximize runtime speed, consider all of the following:
<code>codegen-units = 1</code>, <code>lto = "fat"</code>, an alternative allocator, and <code>panic = "abort"</code>.</li>
<li>If you want to minimize binary size, consider <code>opt-level = "z"</code>,
<code>codegen-units = 1</code>, <code>lto = "fat"</code>, <code>panic = "abort"</code>, and <code>strip = "symbols"</code>.</li>
<li>In either case, consider <code>-C target-cpu=native</code> if broad architecture support
is not needed, and <code>cargo-pgo</code> if it works with your distribution mechanism.</li>
<li>Always use a faster linker if you are on a platform that supports it, because
there are no downsides to doing so.</li>
<li>Use <code>cargo-wizard</code> if you need additional help with these choices.</li>
<li>Benchmark all changes, one at a time, to ensure they have the expected
effects.</li>
</ul>
<p>Finally, <a href="https://github.com/rust-lang/rust/issues/103595">this issue</a> tracks the evolution of the Rust compiler’s own build
configuration. The Rust compiler’s build system is stranger and more complex
than that of most Rust programs. Nonetheless, this issue may be instructive in
showing how build configuration choices can be applied to a large program.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linting"><a class="header" href="#linting">Linting</a></h1>
<p><a href="https://github.com/rust-lang/rust-clippy">Clippy</a> is a collection of lints to catch common mistakes in Rust code. It is
an excellent tool to run on Rust code in general. It can also help with
performance, because a number of the lints relate to code patterns that can
cause sub-optimal performance.</p>
<p>Given that automated detection of problems is preferable to manual detection,
the rest of this book will not mention performance problems that Clippy detects
by default.</p>
<h2 id="basics"><a class="header" href="#basics">Basics</a></h2>
<p>Once installed, it is easy to run:</p>
<pre><code class="language-text">cargo clippy
</code></pre>
<p>The full list of performance lints can be seen by visiting the <a href="https://rust-lang.github.io/rust-clippy/master/">lint list</a> and
deselecting all the lint groups except for “Perf”.</p>
<p>As well as making the code faster, the performance lint suggestions usually
result in code that is simpler and more idiomatic, so they are worth following
even for code that is not executed frequently.</p>
<p>Conversely, some non-performance lint suggestions can improve performance. For
example, the <a href="https://rust-lang.github.io/rust-clippy/master/index.html#ptr_arg"><code>ptr_arg</code></a> style lint suggests changing various container
arguments to slices, such as changing <code>&amp;mut Vec&lt;T&gt;</code> arguments to <code>&amp;mut [T]</code>.
The primary motivation here is that a slice gives a more flexible API, but it
may also result in faster code due to less indirection and better optimization
opportunities for the compiler.
<a href="https://github.com/fschutt/fastblur/pull/3/files"><strong>Example</strong></a>.</p>
<h2 id="disallowing-types"><a class="header" href="#disallowing-types">Disallowing Types</a></h2>
<p>In the following chapters we will see that it is sometimes worth avoiding
certain standard library types in favour of alternatives that are faster. If
you decide to use these alternatives, it is easy to accidentally use the
standard library types in some places by mistake.</p>
<p>You can use Clippy’s <a href="https://rust-lang.github.io/rust-clippy/master/index.html#disallowed_types"><code>disallowed_types</code></a> lint to avoid this problem. For
example, to disallow the use of the standard hash tables (for reasons explained
in the <a href="hashing.html">Hashing</a> section) add a <code>clippy.toml</code> file to your code with the
following line.</p>
<pre><code class="language-toml">disallowed-types = ["std::collections::HashMap", "std::collections::HashSet"]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="profiling"><a class="header" href="#profiling">Profiling</a></h1>
<p>When optimizing a program, you also need a way to determine which parts of the
program are “hot” (executed frequently enough to affect runtime) and worth
modifying. This is best done via profiling.</p>
<h2 id="profilers"><a class="header" href="#profilers">Profilers</a></h2>
<p>There are many different profilers available, each with their strengths and
weaknesses. The following is an incomplete list of profilers that have been
used successfully on Rust programs.</p>
<ul>
<li><a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> is a general-purpose profiler that uses hardware performance counters.
<a href="https://github.com/KDAB/hotspot">Hotspot</a> and <a href="https://profiler.firefox.com/">Firefox Profiler</a> are good for viewing data recorded by perf.
It works on Linux.</li>
<li><a href="https://developer.apple.com/forums/tags/instruments">Instruments</a> is a general-purpose profiler that comes with Xcode on macOS.</li>
<li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html">Intel VTune Profiler</a> is a general-purpose profiler. It works on Windows,
Linux, and macOS.</li>
<li><a href="https://developer.amd.com/amd-uprof/">AMD μProf</a> is a general-purpose profiler. It works on Windows and Linux.</li>
<li><a href="https://github.com/mstange/samply/">samply</a> is a sampling profiler that produces profiles that can be viewed
in the Firefox Profiler. It works on Mac and Linux.</li>
<li><a href="https://github.com/flamegraph-rs/flamegraph">flamegraph</a> is a Cargo command that uses perf/DTrace to profile your
code and then displays the results in a flame graph. It works on Linux and
all platforms that support DTrace (macOS, FreeBSD, NetBSD, and possibly
Windows).</li>
<li><a href="https://www.valgrind.org/docs/manual/cg-manual.html">Cachegrind</a> &amp; <a href="https://www.valgrind.org/docs/manual/cl-manual.html">Callgrind</a> give global, per-function, and per-source-line
instruction counts and simulated cache and branch prediction data. They work
on Linux and some other Unixes.</li>
<li><a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> is good for finding which parts of the code are causing a lot of
allocations, and for giving insight into peak memory usage. It can also be
used to identify hot calls to <code>memcpy</code>. It works on Linux and some other
Unixes. <a href="https://github.com/nnethercote/dhat-rs/">dhat-rs</a> is an experimental alternative that is a little less
powerful and requires minor changes to your Rust program, but works on all
platforms.</li>
<li><a href="https://github.com/KDE/heaptrack">heaptrack</a> and <a href="https://github.com/koute/bytehound">bytehound</a> are heap profiling tools. They work on Linux.</li>
<li><a href="https://github.com/nnethercote/counts/"><code>counts</code></a> supports ad hoc profiling, which combines the use of <code>eprintln!</code>
statement with frequency-based post-processing, which is good for getting
domain-specific insights into parts of your code. It works on all platforms.</li>
<li><a href="https://github.com/plasma-umass/coz">Coz</a> performs <em>causal profiling</em> to measure optimization potential, and has
Rust support via <a href="https://github.com/plasma-umass/coz/tree/master/rust">coz-rs</a>. It works on Linux.</li>
</ul>
<h2 id="debug-info"><a class="header" href="#debug-info">Debug Info</a></h2>
<p>To profile a release build effectively you might need to enable source line
debug info. To do this, add the following lines to your <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
debug = 1
</code></pre>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#debug">Cargo documentation</a> for more details about the <code>debug</code> setting.</p>
<p>Unfortunately, even after doing the above step you won’t get detailed profiling
information for standard library code. This is because shipped versions of the
Rust standard library are not built with debug info.</p>
<p>The most reliable way around this is to build your own version of the compiler
and standard library, following <a href="https://github.com/rust-lang/rust">these instructions</a>, and adding the following
lines to the <code>config.toml</code> file:</p>
<pre><code class="language-toml">[rust]
debuginfo-level = 1
</code></pre>
<p>This is a hassle, but may be worth the effort in some cases.</p>
<p>Alternatively, the unstable <a href="https://doc.rust-lang.org/cargo/reference/unstable.html#build-std">build-std</a> feature lets you compile the standard
library as part of your program’s normal compilation, with the same build
configuration. However, filenames present in the debug info for the standard
library will not point to source code files, because this feature does not also
download standard library source code. So this approach will not help with
profilers such as Cachegrind and Samply that require source code to work fully.</p>
<h2 id="frame-pointers"><a class="header" href="#frame-pointers">Frame pointers</a></h2>
<p>The Rust compiler may optimize away frame pointers, which can hurt the quality
of profiling information such as stack traces. To force the compiler to use
frame pointers, use the <code>-C force-frame-pointers=yes</code> flag. For example:</p>
<pre><code class="language-bash">RUSTFLAGS="-C force-frame-pointers=yes" cargo build --release
</code></pre>
<p>Alternatively, to force the use frame pointers from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for
one or more projects), add these lines:</p>
<pre><code class="language-toml">[build]
rustflags = ["-C", "force-frame-pointers=yes"]
</code></pre>
<h2 id="symbol-demangling"><a class="header" href="#symbol-demangling">Symbol Demangling</a></h2>
<p>Rust uses a form of name mangling to encode function names in compiled code. If
a profiler is unaware of this, its output may contain symbol names beginning
with <code>_ZN</code> or <code>_R</code>, such as <code>_ZN3foo3barE</code> or
<code>_ZN28_$u7b$$u7b$closure$u7d$$u7d$E</code> or
<code>_RMCsno73SFvQKx_1cINtB0_3StrKRe616263_E</code></p>
<p>Names like these can be manually demangled using <a href="https://crates.io/crates/rustfilt"><code>rustfilt</code></a>.</p>
<p>If you are having trouble with symbol demangling while profiling, it may be
worth changing the <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#symbol-mangling-version">mangling format</a> from the default legacy format to the newer
v0 format.</p>
<p>To use the v0 format from the command line, use the <code>-C symbol-mangling-version=v0</code> flag. For example:</p>
<pre><code class="language-bash">RUSTFLAGS="-C symbol-mangling-version=v0" cargo build --release
</code></pre>
<p>Alternatively, to request these instructions from a <a href="https://doc.rust-lang.org/cargo/reference/config.html"><code>config.toml</code></a> file (for
one or more projects), add these lines:</p>
<pre><code class="language-toml">[build]
rustflags = ["-C", "symbol-mangling-version=v0"]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="inlining"><a class="header" href="#inlining">Inlining</a></h1>
<p>Entry to and exit from hot, uninlined functions often accounts for a
non-trivial fraction of execution time. Inlining these functions can provide
small but easy speed wins.</p>
<p>There are four inline attributes that can be used on Rust functions.</p>
<ul>
<li><strong>None</strong>. The compiler will decide itself if the function should be inlined.
This will depend on factors such as the optimization level, the size of the
function, whether the function is generic, and if the inlining is across a
crate boundary.</li>
<li><strong><code>#[inline]</code></strong>. This suggests that the function should be inlined.</li>
<li><strong><code>#[inline(always)]</code></strong>. This strongly suggests that the function should be
inlined.</li>
<li><strong><code>#[inline(never)]</code></strong>. This strongly suggests that the function should not
be inlined.</li>
</ul>
<p>Inline attributes do not guarantee that a function is inlined or not inlined,
but in practice <code>#[inline(always)]</code> will cause inlining in all but the most
exceptional cases.</p>
<p>Inlining is non-transitive. If a function <code>f</code> calls a function <code>g</code> and you want
both functions to be inlined together at a callsite to <code>f</code>, both functions
should be marked with an inline attribute.</p>
<h2 id="simple-cases"><a class="header" href="#simple-cases">Simple Cases</a></h2>
<p>The best candidates for inlining are (a) functions that are very small, or (b)
functions that have a single call site. The compiler will often inline these
functions itself even without an inline attribute. But the compiler cannot
always make the best choices, so attributes are sometimes needed.
<a href="https://github.com/rust-lang/rust/pull/37083/commits/6a4bb35b70862f33ac2491ffe6c55fb210c8490d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50407/commits/e740b97be699c9445b8a1a7af6348ca2d4c460ce"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50564/commits/77c40f8c6f8cc472f6438f7724d60bf3b7718a0c"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/57719/commits/92fd6f9d30d0b6b4ecbcf01534809fb66393f139"><strong>Example 4</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/69256/commits/e761f3af904b3c275bdebc73bb29ffc45384945d"><strong>Example 5</strong></a>.</p>
<p>Cachegrind is a good profiler for determining if a function is inlined. When
looking at Cachegrind’s output, you can tell that a function has been inlined
if (and only if) its first and last lines are <em>not</em> marked with event counts.
For example:</p>
<pre><code class="language-text">      .  #[inline(always)]
      .  fn inlined(x: u32, y: u32) -&gt; u32 {
700,000      eprintln!("inlined: {} + {}", x, y);
200,000      x + y
      .  }
      .  
      .  #[inline(never)]
400,000  fn not_inlined(x: u32, y: u32) -&gt; u32 {
700,000      eprintln!("not_inlined: {} + {}", x, y);
200,000      x + y
200,000  }
</code></pre>
<p>You should measure again after adding inline attributes, because the effects
can be unpredictable. Sometimes it has no effect because a nearby function that
was previously inlined no longer is. Sometimes it slows the code down. Inlining
can also affect compile times, especially cross-crate inlining which involves
duplicating internal representations of the functions.</p>
<h2 id="harder-cases"><a class="header" href="#harder-cases">Harder Cases</a></h2>
<p>Sometimes you have a function that is large and has multiple call sites, but
only one call site is hot. You would like to inline the hot call site for
speed, but not inline the cold call sites to avoid unnecessary code bloat. The
way to handle this is to split the function always-inlined and never-inlined
variants, with the latter calling the former.</p>
<p>For example, this function:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn one() {};
</span><span class="boring">fn two() {};
</span><span class="boring">fn three() {};
</span>fn my_function() {
    one();
    two();
    three();
}
<span class="boring">}</span></code></pre></pre>
<p>Would become these two functions:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn one() {};
</span><span class="boring">fn two() {};
</span><span class="boring">fn three() {};
</span>// Use this at the hot call site.
#[inline(always)]
fn inlined_my_function() {
    one();
    two();
    three();
}

// Use this at the cold call sites.
#[inline(never)]
fn uninlined_my_function() {
    inlined_my_function();
}
<span class="boring">}</span></code></pre></pre>
<p><a href="https://github.com/rust-lang/rust/pull/53513/commits/b73843f9422fb487b2d26ac2d65f79f73a4c9ae3"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64420/commits/a2261ad66400c3145f96ebff0d9b75e910fa89dd"><strong>Example 2</strong></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hashing"><a class="header" href="#hashing">Hashing</a></h1>
<p><code>HashSet</code> and <code>HashMap</code> are two widely-used types. The default hashing
algorithm is not specified, but at the time of writing the default is an
algorithm called <a href="https://en.wikipedia.org/wiki/SipHash">SipHash 1-3</a>. This algorithm is high quality—it provides high
protection against collisions—but is relatively slow, particularly for short keys
such as integers.</p>
<p>If profiling shows that hashing is hot, and <a href="https://en.wikipedia.org/wiki/Collision_attack">HashDoS attacks</a> are not a concern
for your application, the use of hash tables with faster hash algorithms can
provide large speed wins.</p>
<ul>
<li><a href="https://crates.io/crates/rustc-hash"><code>rustc-hash</code></a> provides <code>FxHashSet</code> and <code>FxHashMap</code> types that are drop-in
replacements for <code>HashSet</code> and <code>HashMap</code>. Its hashing algorithm is
low-quality but very fast, especially for integer keys, and has been found to
out-perform all other hash algorithms within rustc. (<a href="https://crates.io/crates/fxhash"><code>fxhash</code></a> is an older,
less well maintained implementation of the same algorithm and types.)</li>
<li><a href="https://crates.io/crates/fnv"><code>fnv</code></a> provides <code>FnvHashSet</code> and <code>FnvHashMap</code> types. Its hashing algorithm
is higher quality than <code>rustc-hash</code>’s but a little slower.</li>
<li><a href="https://crates.io/crates/ahash"><code>ahash</code></a> provides <code>AHashSet</code> and <code>AHashMap</code>. Its hashing algorithm can take
advantage of AES instruction support that is available on some processors.</li>
</ul>
<p>If hashing performance is important in your program, it is worth trying more
than one of these alternatives. For example, the following results were seen in
rustc.</p>
<ul>
<li>The switch from <code>fnv</code> to <code>fxhash</code> gave <a href="https://github.com/rust-lang/rust/pull/37229/commits/00e48affde2d349e3b3bfbd3d0f6afb5d76282a7">speedups of up to 6%</a>.</li>
<li>An attempt to switch from <code>fxhash</code> to <code>ahash</code> resulted in <a href="https://github.com/rust-lang/rust/issues/69153#issuecomment-589504301">slowdowns of
1-4%</a>.</li>
<li>An attempt to switch from <code>fxhash</code> back to the default hasher resulted in
<a href="https://github.com/rust-lang/rust/issues/69153#issuecomment-589338446">slowdowns ranging from 4-84%</a>!</li>
</ul>
<p>If you decide to universally use one of the alternatives, such as
<code>FxHashSet</code>/<code>FxHashMap</code>, it is easy to accidentally use <code>HashSet</code>/<code>HashMap</code> in
some places. You can <a href="linting.html#disallowing-types">use Clippy</a> to avoid this problem.</p>
<p>Some types don’t need hashing. For example, you might have a newtype that wraps
an integer and the integer values are random, or close to random. For such a
type, the distribution of the hashed values won’t be that different to the
distribution of the values themselves. In this case the <a href="https://crates.io/crates/nohash-hasher"><code>nohash_hasher</code></a> crate
can be useful.</p>
<p>Hash function design is a complex topic and is beyond the scope of this book.
The <a href="https://github.com/tkaitchuck/aHash/blob/master/compare/readme.md"><code>ahash</code> documentation</a> has a good discussion.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="heap-allocations"><a class="header" href="#heap-allocations">Heap Allocations</a></h1>
<p>Heap allocations are moderately expensive. The exact details depend on which
allocator is in use, but each allocation (and deallocation) typically involves
acquiring a global lock, doing some non-trivial data structure manipulation,
and possibly executing a system call. Small allocations are not necessarily
cheaper than large allocations. It is worth understanding which Rust data
structures and operations cause allocations, because avoiding them can greatly
improve performance.</p>
<p>The <a href="https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/">Rust Container Cheat Sheet</a> has visualizations of common Rust types, and
is an excellent companion to the following sections.</p>
<h2 id="profiling-1"><a class="header" href="#profiling-1">Profiling</a></h2>
<p>If a general-purpose profiler shows <code>malloc</code>, <code>free</code>, and related functions as
hot, then it is likely worth trying to reduce the allocation rate and/or using
an alternative allocator.</p>
<p><a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> is an excellent profiler to use when reducing allocation rates. It works
on Linux and some other Unixes. It precisely identifies hot allocation
sites and their allocation rates. Exact results will vary, but experience with
rustc has shown that reducing allocation rates by 10 allocations per million
instructions executed can have measurable performance improvements (e.g. ~1%).</p>
<p>Here is some example output from DHAT.</p>
<pre><code class="language-text">AP 1.1/25 (2 children) {
  Total:     54,533,440 bytes (4.02%, 2,714.28/Minstr) in 458,839 blocks (7.72%, 22.84/Minstr), avg size 118.85 bytes, avg lifetime 1,127,259,403.64 instrs (5.61% of program duration)
  At t-gmax: 0 bytes (0%) in 0 blocks (0%), avg size 0 bytes
  At t-end:  0 bytes (0%) in 0 blocks (0%), avg size 0 bytes
  Reads:     15,993,012 bytes (0.29%, 796.02/Minstr), 0.29/byte
  Writes:    20,974,752 bytes (1.03%, 1,043.97/Minstr), 0.38/byte
  Allocated at {
    #1: 0x95CACC9: alloc (alloc.rs:72)
    #2: 0x95CACC9: alloc (alloc.rs:148)
    #3: 0x95CACC9: reserve_internal&lt;syntax::tokenstream::TokenStream,alloc::alloc::Global&gt; (raw_vec.rs:669)
    #4: 0x95CACC9: reserve&lt;syntax::tokenstream::TokenStream,alloc::alloc::Global&gt; (raw_vec.rs:492)
    #5: 0x95CACC9: reserve&lt;syntax::tokenstream::TokenStream&gt; (vec.rs:460)
    #6: 0x95CACC9: push&lt;syntax::tokenstream::TokenStream&gt; (vec.rs:989)
    #7: 0x95CACC9: parse_token_trees_until_close_delim (tokentrees.rs:27)
    #8: 0x95CACC9: syntax::parse::lexer::tokentrees::&lt;impl syntax::parse::lexer::StringReader&lt;'a&gt;&gt;::parse_token_tree (tokentrees.rs:81)
  }
}
</code></pre>
<p>It is beyond the scope of this book to describe everything in this example, but
it should be clear that DHAT gives a wealth of information about allocations,
such as where and how often they happen, how big they are, how long they live
for, and how often they are accessed.</p>
<h2 id="box"><a class="header" href="#box"><code>Box</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/boxed/struct.Box.html"><code>Box</code></a> is the simplest heap-allocated type. A <code>Box&lt;T&gt;</code> value is a <code>T</code> value
that is allocated on the heap.</p>
<p>It is sometimes worth boxing one or more fields in a struct or enum fields to
make a type smaller. (See the <a href="type-sizes.html">Type Sizes</a> chapter for more
about this.)</p>
<p>Other than that, <code>Box</code> is straightforward and does not offer much scope for
optimizations.</p>
<h2 id="rcarc"><a class="header" href="#rcarc"><code>Rc</code>/<code>Arc</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a>/<a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>Arc</code></a> are similar to <code>Box</code>, but the value on the heap is accompanied by
two reference counts. They allow value sharing, which can be an effective way
to reduce memory usage.</p>
<p>However, if used for values that are rarely shared, they can increase allocation
rates by heap allocating values that might otherwise not be heap-allocated.
<a href="https://github.com/rust-lang/rust/pull/37373/commits/c440a7ae654fb641e68a9ee53b03bf3f7133c2fe"><strong>Example</strong></a>.</p>
<p>Unlike <code>Box</code>, calling <code>clone</code> on an <code>Rc</code>/<code>Arc</code> value does not involve an
allocation. Instead, it merely increments a reference count.</p>
<h2 id="vec"><a class="header" href="#vec"><code>Vec</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a> is a heap-allocated type with a great deal of scope for optimizing the
number of allocations, and/or minimizing the amount of wasted space. To do this
requires understanding how its elements are stored.</p>
<p>A <code>Vec</code> contains three words: a length, a capacity, and a pointer. The pointer
will point to heap-allocated memory if the capacity is nonzero and the element
size is nonzero; otherwise, it will not point to allocated memory.</p>
<p>Even if the <code>Vec</code> itself is not heap-allocated, the elements (if present and
nonzero-sized) always will be. If nonzero-sized elements are present, the
memory holding those elements may be larger than necessary, providing space for
additional future elements. The number of elements present is the length, and
the number of elements that could be held without reallocating is the capacity.</p>
<p>When the vector needs to grow beyond its current capacity, the elements will be
copied into a larger heap allocation, and the old heap allocation will be
freed.</p>
<h3 id="vec-growth"><a class="header" href="#vec-growth"><code>Vec</code> Growth</a></h3>
<p>A new, empty <code>Vec</code> created by the common means
(<a href="https://doc.rust-lang.org/std/macro.vec.html"><code>vec![]</code></a>
or <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.new"><code>Vec::new</code></a> or <a href="https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default"><code>Vec::default</code></a>) has a length and capacity of zero, and no
heap allocation is required. If you repeatedly push individual elements onto
the end of the <code>Vec</code>, it will periodically reallocate. The growth strategy is
not specified, but at the time of writing it uses a quasi-doubling strategy
resulting in the following capacities: 0, 4, 8, 16, 32, 64, and so on. (It
skips directly from 0 to 4, instead of going via 1 and 2, because this <a href="https://github.com/rust-lang/rust/pull/72227">avoids
many allocations</a> in practice.) As a vector grows, the frequency of
reallocations will decrease exponentially, but the amount of possibly-wasted
excess capacity will increase exponentially.</p>
<p>This growth strategy is typical for growable data structures and reasonable in
the general case, but if you know in advance the likely length of a vector you
can often do better. If you have a hot vector allocation site (e.g. a hot
<a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.push"><code>Vec::push</code></a> call), it is worth using <a href="https://doc.rust-lang.org/std/macro.eprintln.html"><code>eprintln!</code></a> to print the vector length
at that site and then doing some post-processing (e.g. with <a href="https://github.com/nnethercote/counts/"><code>counts</code></a>) to
determine the length distribution. For example, you might have many short
vectors, or you might have a smaller number of very long vectors, and the best
way to optimize the allocation site will vary accordingly.</p>
<h3 id="short-vecs"><a class="header" href="#short-vecs">Short <code>Vec</code>s</a></h3>
<p>If you have many short vectors, you can use the <code>SmallVec</code> type from the
<a href="https://crates.io/crates/smallvec"><code>smallvec</code></a> crate. <code>SmallVec&lt;[T; N]&gt;</code> is a drop-in replacement for <code>Vec</code> that
can store <code>N</code> elements within the <code>SmallVec</code> itself, and then switches to a
heap allocation if the number of elements exceeds that. (Note also that
<code>vec![]</code> literals must be replaced with <code>smallvec![]</code> literals.)
<a href="https://github.com/rust-lang/rust/pull/50565/commits/78262e700dc6a7b57e376742f344e80115d2d3f2"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/55383/commits/526dc1421b48e3ee8357d58d997e7a0f4bb26915"><strong>Example 2</strong></a>.</p>
<p><code>SmallVec</code> reliably reduces the allocation rate when used appropriately, but
its use does not guarantee improved performance. It is slightly slower than
<code>Vec</code> for normal operations because it must always check if the elements are
heap-allocated or not. Also, If <code>N</code> is high or <code>T</code> is large, then the
<code>SmallVec&lt;[T; N]&gt;</code> itself can be larger than <code>Vec&lt;T&gt;</code>, and copying of
<code>SmallVec</code> values will be slower. As always, benchmarking is required to
confirm that an optimization is effective.</p>
<p>If you have many short vectors <em>and</em> you precisely know their maximum length,
<code>ArrayVec</code> from the <a href="https://crates.io/crates/arrayvec"><code>arrayvec</code></a> crate is a better choice than <code>SmallVec</code>. It
does not require the fallback to heap allocation, which makes it a little
faster.
<a href="https://github.com/rust-lang/rust/pull/74310/commits/c492ca40a288d8a85353ba112c4d38fe87ef453e"><strong>Example</strong></a>.</p>
<h3 id="longer-vecs"><a class="header" href="#longer-vecs">Longer <code>Vec</code>s</a></h3>
<p>If you know the minimum or exact size of a vector, you can reserve a specific
capacity with <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.with_capacity"><code>Vec::with_capacity</code></a>, <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.reserve"><code>Vec::reserve</code></a>, or
<a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.reserve_exact"><code>Vec::reserve_exact</code></a>. For example, if you know a vector will grow to have at
least 20 elements, these functions can immediately provide a vector with a
capacity of at least 20 using a single allocation, whereas pushing the items
one at a time would result in four allocations (for capacities of 4, 8, 16, and
32).
<a href="https://github.com/rust-lang/rust/pull/77990/commits/a7f2bb634308a5f05f2af716482b67ba43701681"><strong>Example</strong></a>.</p>
<p>If you know the maximum length of a vector, the above functions also let you
not allocate excess space unnecessarily. Similarly, <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.shrink_to_fit"><code>Vec::shrink_to_fit</code></a> can be
used to minimize wasted space, but note that it may cause a reallocation.</p>
<h2 id="string"><a class="header" href="#string"><code>String</code></a></h2>
<p>A <a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a> contains heap-allocated bytes. The representation and operation of
<code>String</code> are very similar to that of <code>Vec&lt;u8&gt;</code>. Many <code>Vec</code> methods relating to
growth and capacity have equivalents for <code>String</code>, such as
<a href="https://doc.rust-lang.org/std/string/struct.String.html#method.with_capacity"><code>String::with_capacity</code></a>.</p>
<p>The <code>SmallString</code> type from the <a href="https://crates.io/crates/smallstr"><code>smallstr</code></a> crate is similar to the <code>SmallVec</code>
type.</p>
<p>The <code>String</code> type from the <a href="https://crates.io/crates/smartstring"><code>smartstring</code></a> crate is a drop-in replacement for
<code>String</code> that avoids heap allocations for strings with less than three words’
worth of characters. On 64-bit platforms, this is any string that is less than
24 bytes, which includes all strings containing 23 or fewer ASCII characters.
<a href="https://github.com/djc/topfew-rs/commit/803fd566e9b889b7ba452a2a294a3e4df76e6c4c"><strong>Example</strong></a>.</p>
<p>Note that the <code>format!</code> macro produces a <code>String</code>, which means it performs an
allocation. If you can avoid a <code>format!</code> call by using a string literal, that
will avoid this allocation.
<a href="https://github.com/rust-lang/rust/pull/55905/commits/c6862992d947331cd6556f765f6efbde0a709cf9"><strong>Example</strong></a>.
<a href="https://doc.rust-lang.org/std/macro.format_args.html"><code>std::format_args</code></a> and/or the <a href="https://crates.io/crates/lazy_format"><code>lazy_format</code></a> crate may help with this.</p>
<h2 id="hash-tables"><a class="header" href="#hash-tables">Hash Tables</a></h2>
<p><a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html"><code>HashSet</code></a> and <a href="https://doc.rust-lang.org/std/collections/struct.HashMap.html"><code>HashMap</code></a> are hash tables. Their representation and
operations are similar to those of <code>Vec</code>, in terms of allocations: they have
a single contiguous heap allocation, holding keys and values, which is
reallocated as necessary as the table grows. Many <code>Vec</code> methods relating to
growth and capacity have equivalents for <code>HashSet</code>/<code>HashMap</code>, such as
<a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.with_capacity"><code>HashSet::with_capacity</code></a>.</p>
<h2 id="clone"><a class="header" href="#clone"><code>clone</code></a></h2>
<p>Calling <a href="https://doc.rust-lang.org/std/clone/trait.Clone.html#tymethod.clone"><code>clone</code></a> on a value that contains heap-allocated memory typically
involves additional allocations. For example, calling <code>clone</code> on a non-empty
<code>Vec</code> requires a new allocation for the elements (but note that the capacity of
the new <code>Vec</code> might not be the same as the capacity of the original <code>Vec</code>). The
exception is <code>Rc</code>/<code>Arc</code>, where a <code>clone</code> call just increments the reference
count.</p>
<p><a href="https://doc.rust-lang.org/std/clone/trait.Clone.html#method.clone_from"><code>clone_from</code></a> is an alternative to <code>clone</code>. <code>a.clone_from(&amp;b)</code> is equivalent
to <code>a = b.clone()</code> but may avoid unnecessary allocations. For example, if you
want to clone one <code>Vec</code> over the top of an existing <code>Vec</code>, the existing <code>Vec</code>’s
heap allocation will be reused if possible, as the following example shows.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut v1: Vec&lt;u32&gt; = Vec::with_capacity(99);
let v2: Vec&lt;u32&gt; = vec![1, 2, 3];
v1.clone_from(&amp;v2); // v1's allocation is reused
assert_eq!(v1.capacity(), 99);
<span class="boring">}</span></code></pre></pre>
<p>Although <code>clone</code> usually causes allocations, it is a reasonable thing to use in
many circumstances and can often make code simpler. Use profiling data to see
which <code>clone</code> calls are hot and worth taking the effort to avoid.</p>
<p>Sometimes Rust code ends up containing unnecessary <code>clone</code> calls, due to (a)
programmer error, or (b) changes in the code that render previously-necessary
<code>clone</code> calls unnecessary. If you see a hot <code>clone</code> call that does not seem
necessary, sometimes it can simply be removed.
<a href="https://github.com/rust-lang/rust/pull/37318/commits/e382267cfb9133ef12d59b66a2935ee45b546a61"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/37705/commits/11c1126688bab32f76dbe1a973906c7586da143f"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64302/commits/36b37e22de92b584b9cf4464ed1d4ad317b798be"><strong>Example 3</strong></a>.</p>
<h2 id="to_owned"><a class="header" href="#to_owned"><code>to_owned</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/borrow/trait.ToOwned.html#tymethod.to_owned"><code>ToOwned::to_owned</code></a> is implemented for many common types. It creates owned
data from borrowed data, usually by cloning, and therefore often causes heap
allocations. For example, it can be used to create a <code>String</code> from a <code>&amp;str</code>.</p>
<p>Sometimes <code>to_owned</code> calls (and related calls such as <code>clone</code> and <code>to_string</code>)
can be avoided by storing a reference to borrowed data in a struct rather than
an owned copy. This requires lifetime annotations on the struct, complicating
the code, and should only be done when profiling and benchmarking shows that it
is worthwhile.
<a href="https://github.com/rust-lang/rust/pull/50855/commits/6872377357dbbf373cfd2aae352cb74cfcc66f34"><strong>Example</strong></a>.</p>
<h2 id="cow"><a class="header" href="#cow"><code>Cow</code></a></h2>
<p>Sometimes code deals with a mixture of borrowed and owned data. Imagine a
vector of error messages, some of which are static string literals and some of
which are constructed with <code>format!</code>. The obvious representation is
<code>Vec&lt;String&gt;</code>, as the following example shows.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut errors: Vec&lt;String&gt; = vec![];
errors.push("something went wrong".to_string());
errors.push(format!("something went wrong on line {}", 100));
<span class="boring">}</span></code></pre></pre>
<p>That requires a <code>to_string</code> call to promote the static string literal to a
<code>String</code>, which incurs an allocation.</p>
<p>Instead you can use the <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow</code></a> type, which can hold either borrowed or owned
data. A borrowed value <code>x</code> is wrapped with <code>Cow::Borrowed(x)</code>, and an owned
value <code>y</code> is wrapped with <code>Cow::Owned(y)</code>. <code>Cow</code> also implements the <code>From&lt;T&gt;</code>
trait for various string, slice, and path types, so you can usually use <code>into</code>
as well. (Or <code>Cow::from</code>, which is longer but results in more readable code,
because it makes the type clearer.) The following example puts all this together.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::borrow::Cow;
let mut errors: Vec&lt;Cow&lt;'static, str&gt;&gt; = vec![];
errors.push(Cow::Borrowed("something went wrong"));
errors.push(Cow::Owned(format!("something went wrong on line {}", 100)));
errors.push(Cow::from("something else went wrong"));
errors.push(format!("something else went wrong on line {}", 101).into());
<span class="boring">}</span></code></pre></pre>
<p><code>errors</code> now holds a mixture of borrowed and owned data without requiring any
extra allocations. This example involves <code>&amp;str</code>/<code>String</code>, but other pairings
such as <code>&amp;[T]</code>/<code>Vec&lt;T&gt;</code> and <code>&amp;Path</code>/<code>PathBuf</code> are also possible.</p>
<p><a href="https://github.com/rust-lang/rust/pull/37064/commits/b043e11de2eb2c60f7bfec5e15960f537b229e20"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/56336/commits/787959c20d062d396b97a5566e0a766d963af022"><strong>Example 2</strong></a>.</p>
<p>All of the above applies if the data is immutable. But <code>Cow</code> also allows
borrowed data to be promoted to owned data if it needs to be mutated.
<a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html#method.to_mut"><code>Cow::to_mut</code></a> will obtain a mutable reference to an owned value, cloning if
necessary. This is called “clone-on-write”, which is where the name <code>Cow</code> comes
from.</p>
<p>This clone-on-write behaviour is useful when you have some borrowed data, such
as a <code>&amp;str</code>, that is mostly read-only but occasionally needs to be modified.</p>
<p><a href="https://github.com/rust-lang/rust/pull/50855/commits/ad471452ba6fbbf91ad566dc4bdf1033a7281811"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/68848/commits/67da45f5084f98eeb20cc6022d68788510dc832a"><strong>Example 2</strong></a>.</p>
<p>Finally, because <code>Cow</code> implements <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html"><code>Deref</code></a>, you can call methods directly on
the data it encloses.</p>
<p><code>Cow</code> can be fiddly to get working, but it is often worth the effort.</p>
<h2 id="reusing-collections"><a class="header" href="#reusing-collections">Reusing Collections</a></h2>
<p>Sometimes you need to build up a collection such as a <code>Vec</code> in stages. It is
usually better to do this by modifying a single <code>Vec</code> than by building multiple
<code>Vec</code>s and then combining them.</p>
<p>For example, if you have a function <code>do_stuff</code> that produces a <code>Vec</code> that might
be called multiple times:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn do_stuff(x: u32, y: u32) -&gt; Vec&lt;u32&gt; {
    vec![x, y]
}
<span class="boring">}</span></code></pre></pre>
<p>It might be better to instead modify a passed-in <code>Vec</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn do_stuff(x: u32, y: u32, vec: &amp;mut Vec&lt;u32&gt;) {
    vec.push(x);
    vec.push(y);
}
<span class="boring">}</span></code></pre></pre>
<p>Sometimes it is worth keeping around a “workhorse” collection that can be
reused. For example, if a <code>Vec</code> is needed for each iteration of a loop, you
could declare the <code>Vec</code> outside the loop, use it within the loop body, and then
call <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.clear"><code>clear</code></a> at the end of the loop body (to empty the <code>Vec</code> without affecting
its capacity). This avoids allocations at the cost of obscuring the fact that
each iteration’s usage of the <code>Vec</code> is unrelated to the others.
<a href="https://github.com/rust-lang/rust/pull/77990/commits/45faeb43aecdc98c9e3f2b24edf2ecc71f39d323"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/51870/commits/b0c78120e3ecae5f4043781f7a3f79e2277293e7"><strong>Example 2</strong></a>.</p>
<p>Similarly, it is sometimes worth keeping a workhorse collection within a
struct, to be reused in one or more methods that are called repeatedly.</p>
<h2 id="reading-lines-from-a-file"><a class="header" href="#reading-lines-from-a-file">Reading Lines from a File</a></h2>
<p><a href="https://doc.rust-lang.org/stable/std/io/trait.BufRead.html#method.lines"><code>BufRead::lines</code></a> makes it easy to read a file one line at a time:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">fn process(_: &amp;str) {}
</span>use std::io::{self, BufRead};
let mut lock = io::stdin().lock();
for line in lock.lines() {
    process(&amp;line?);
}
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>But the iterator it produces returns <code>io::Result&lt;String&gt;</code>, which means it
allocates for every line in the file.</p>
<p>An alternative is to use a workhorse <code>String</code> in a loop over
<a href="https://doc.rust-lang.org/stable/std/io/trait.BufRead.html#method.read_line"><code>BufRead::read_line</code></a>:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">fn process(_: &amp;str) {}
</span>use std::io::{self, BufRead};
let mut lock = io::stdin().lock();
let mut line = String::new();
while lock.read_line(&amp;mut line)? != 0 {
    process(&amp;line);
    line.clear();
}
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>This reduces the number of allocations to at most a handful, and possibly just
one. (The exact number depends on how many times <code>line</code> needs to be
reallocated, which depends on the distribution of line lengths in the file.)</p>
<p>This will only work if the loop body can operate on a <code>&amp;str</code>, rather than a
<code>String</code>.</p>
<p><a href="https://github.com/nnethercote/counts/commit/7d39bbb1867720ef3b9799fee739cd717ad1539a"><strong>Example</strong></a>.</p>
<h2 id="using-an-alternative-allocator"><a class="header" href="#using-an-alternative-allocator">Using an Alternative Allocator</a></h2>
<p>It is also possible to improve heap allocation performance without changing
your code, simply by using a different allocator. See the <a href="build-configuration.html#alternative-allocators">Alternative
Allocators</a> section for details.</p>
<h2 id="avoiding-regressions"><a class="header" href="#avoiding-regressions">Avoiding Regressions</a></h2>
<p>To ensure the number and/or size of allocations done by your code doesn’t
increase unintentionally, you can use the <em>heap usage testing</em> feature of
<a href="https://crates.io/crates/dhat">dhat-rs</a> to write tests that check particular code snippets allocate the
expected amount of heap memory.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="type-sizes"><a class="header" href="#type-sizes">Type Sizes</a></h1>
<p>Shrinking oft-instantiated types can help performance.</p>
<p>For example, if memory usage is high, a heap profiler like <a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> can identify
the hot allocation points and the types involved. Shrinking these types can
reduce peak memory usage, and possibly improve performance by reducing memory
traffic and cache pressure.</p>
<p>Furthermore, Rust types that are larger than 128 bytes are copied with <code>memcpy</code>
rather than inline code. If <code>memcpy</code> shows up in non-trivial amounts in
profiles, DHAT’s “copy profiling” mode will tell you exactly where the hot
<code>memcpy</code> calls are and the types involved. Shrinking these types to 128 bytes
or less can make the code faster by avoiding <code>memcpy</code> calls and reducing memory
traffic.</p>
<h2 id="measuring-type-sizes"><a class="header" href="#measuring-type-sizes">Measuring Type Sizes</a></h2>
<p><a href="https://doc.rust-lang.org/std/mem/fn.size_of.html"><code>std::mem::size_of</code></a> gives the size of a type, in bytes, but often you want to
know the exact layout as well. For example, an enum might be surprisingly large
due to a single outsized variant.</p>
<p>The <code>-Zprint-type-sizes</code> option does exactly this. It isn’t enabled on release
versions of rustc, so you’ll need to use a nightly version of rustc. Here is
one possible invocation via Cargo:</p>
<pre><code class="language-text">RUSTFLAGS=-Zprint-type-sizes cargo +nightly build --release
</code></pre>
<p>And here is a possible invocation of rustc:</p>
<pre><code class="language-text">rustc +nightly -Zprint-type-sizes input.rs
</code></pre>
<p>It will print out details of the size, layout, and alignment of all types in
use. For example, for this type:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum E {
    A,
    B(i32),
    C(u64, u8, u64, u8),
    D(Vec&lt;u32&gt;),
}
<span class="boring">}</span></code></pre></pre>
<p>it prints the following, plus information about a few built-in types.</p>
<pre><code class="language-text">print-type-size type: `E`: 32 bytes, alignment: 8 bytes
print-type-size     discriminant: 1 bytes
print-type-size     variant `D`: 31 bytes
print-type-size         padding: 7 bytes
print-type-size         field `.0`: 24 bytes, alignment: 8 bytes
print-type-size     variant `C`: 23 bytes
print-type-size         field `.1`: 1 bytes
print-type-size         field `.3`: 1 bytes
print-type-size         padding: 5 bytes
print-type-size         field `.0`: 8 bytes, alignment: 8 bytes
print-type-size         field `.2`: 8 bytes
print-type-size     variant `B`: 7 bytes
print-type-size         padding: 3 bytes
print-type-size         field `.0`: 4 bytes, alignment: 4 bytes
print-type-size     variant `A`: 0 bytes
</code></pre>
<p>The output shows the following.</p>
<ul>
<li>The size and alignment of the type.</li>
<li>For enums, the size of the discriminant.</li>
<li>For enums, the size of each variant (sorted from largest to smallest).</li>
<li>The size, alignment, and ordering of all fields. (Note that the compiler has
reordered variant <code>C</code>’s fields to minimize the size of <code>E</code>.)</li>
<li>The size and location of all padding.</li>
</ul>
<p>Alternatively, the <a href="https://crates.io/crates/top-type-sizes">top-type-sizes</a> crate can be used to display the output in
a more compact form.</p>
<p>Once you know the layout of a hot type, there are multiple ways to shrink it.</p>
<h2 id="field-ordering"><a class="header" href="#field-ordering">Field Ordering</a></h2>
<p>The Rust compiler automatically sorts the fields in struct and enums to
minimize their sizes (unless the <code>#[repr(C)]</code> attribute is specified), so you
do not have to worry about field ordering. But there are other ways to minimize
the size of hot types.</p>
<h2 id="smaller-enums"><a class="header" href="#smaller-enums">Smaller Enums</a></h2>
<p>If an enum has an outsized variant, consider boxing one or more fields. For
example, you could change this type:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>type LargeType = [u8; 100];
enum A {
    X,
    Y(i32),
    Z(i32, LargeType),
}
<span class="boring">}</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">type LargeType = [u8; 100];
</span>enum A {
    X,
    Y(i32),
    Z(Box&lt;(i32, LargeType)&gt;),
}
<span class="boring">}</span></code></pre></pre>
<p>This reduces the type size at the cost of requiring an extra heap allocation
for the <code>A::Z</code> variant. This is more likely to be a net performance win if the
<code>A::Z</code> variant is relatively rare. The <code>Box</code> will also make <code>A::Z</code> slightly
less ergonomic to use, especially in <code>match</code> patterns.
<a href="https://github.com/rust-lang/rust/pull/37445/commits/a920e355ea837a950b484b5791051337cd371f5d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/55346/commits/38d9277a77e982e49df07725b62b21c423b6428e"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64302/commits/b972ac818c98373b6d045956b049dc34932c41be"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64374/commits/2fcd870711ce267c79408ec631f7eba8e0afcdf6"><strong>Example 4</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64394/commits/7f0637da5144c7435e88ea3805021882f077d50c"><strong>Example 5</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/71942/commits/27ae2f0d60d9201133e1f9ec7a04c05c8e55e665"><strong>Example 6</strong></a>.</p>
<h2 id="smaller-integers"><a class="header" href="#smaller-integers">Smaller Integers</a></h2>
<p>It is often possible to shrink types by using smaller integer types. For
example, while it is most natural to use <code>usize</code> for indices, it is often
reasonable to stores indices as <code>u32</code>, <code>u16</code>, or even <code>u8</code>, and then coerce to
<code>usize</code> at use points.
<a href="https://github.com/rust-lang/rust/pull/49993/commits/4d34bfd00a57f8a8bdb60ec3f908c5d4256f8a9a"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50981/commits/8d0fad5d3832c6c1f14542ea0be038274e454524"><strong>Example 2</strong></a>.</p>
<h2 id="boxed-slices"><a class="header" href="#boxed-slices">Boxed Slices</a></h2>
<p>Rust vectors contain three words: a length, a capacity, and a pointer. If you
have a vector that is unlikely to be changed in the future, you can convert it
to a <em>boxed slice</em> with <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.into_boxed_slice"><code>Vec::into_boxed_slice</code></a>. A boxed slice contains only
two words, a length and a pointer. Any excess element capacity is dropped,
which may cause a reallocation.</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::mem::{size_of, size_of_val};
</span>let v: Vec&lt;u32&gt; = vec![1, 2, 3];
assert_eq!(size_of_val(&amp;v), 3 * size_of::&lt;usize&gt;());

let bs: Box&lt;[u32]&gt; = v.into_boxed_slice();
assert_eq!(size_of_val(&amp;bs), 2 * size_of::&lt;usize&gt;());
<span class="boring">}</span></code></pre></pre>
<p>The boxed slice can be converted back to a vector with <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.into_vec"><code>slice::into_vec</code></a>
without any cloning or a reallocation.</p>
<h2 id="thinvec"><a class="header" href="#thinvec"><code>ThinVec</code></a></h2>
<p>An alternative to boxed slices is <code>ThinVec</code>, from the <a href="https://crates.io/crates/thin-vec"><code>thin_vec</code></a> crate. It is
functionally equivalent to <code>Vec</code>, but stores the length and capacity in the
same allocation as the elements (if there are any). This means that
<code>size_of::&lt;ThinVec&lt;T&gt;&gt;</code> is only one word.</p>
<p><code>ThinVec</code> is a good choice within oft-instantiated types for vectors that are
often empty. It can also be used to shrink the largest variant of an enum, if
that variant contains a <code>Vec</code>.</p>
<h2 id="avoiding-regressions-1"><a class="header" href="#avoiding-regressions-1">Avoiding Regressions</a></h2>
<p>If a type is hot enough that its size can affect performance, it is a good idea
to use a static assertion to ensure that it does not accidentally regress. The
following example uses a macro from the <a href="https://crates.io/crates/static_assertions"><code>static_assertions</code></a> crate.</p>
<pre><code class="language-rust ignore">  // This type is used a lot. Make sure it doesn't unintentionally get bigger.
  #[cfg(target_arch = "x86_64")]
  static_assertions::assert_eq_size!(HotType, [u8; 64]);</code></pre>
<p>The <code>cfg</code> attribute is important, because type sizes can vary on different
platforms. Restricting the assertion to <code>x86_64</code> (which is typically the most
widely-used platform) is likely to be good enough to prevent regressions in
practice.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="standard-library-types"><a class="header" href="#standard-library-types">Standard Library Types</a></h1>
<p>It is worth reading through the documentation for common standard library
types—such as <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a>, <a href="https://doc.rust-lang.org/std/option/enum.Option.html"><code>Option</code></a>, <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a>, and <a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a>/<a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>Arc</code></a>—to find interesting
functions that can sometimes be used to improve performance.</p>
<p>It is also worth knowing about high-performance alternatives to standard
library types, such as <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>Mutex</code></a>, <a href="https://doc.rust-lang.org/std/sync/struct.RwLock.html"><code>RwLock</code></a>, <a href="https://doc.rust-lang.org/std/sync/struct.Condvar.html"><code>Condvar</code></a>, and
<a href="https://doc.rust-lang.org/std/sync/struct.Once.html"><code>Once</code></a>.</p>
<h2 id="vec-1"><a class="header" href="#vec-1"><code>Vec</code></a></h2>
<p>The best way to create a zero-filled <code>Vec</code> of length <code>n</code> is with <code>vec![0; n]</code>.
This is simple and probably <a href="https://github.com/rust-lang/rust/issues/54628">as fast or faster</a> than alternatives, such as
using <code>resize</code>, <code>extend</code>, or anything involving <code>unsafe</code>, because it can use OS
assistance.</p>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.remove"><code>Vec::remove</code></a> removes an element at a particular index and shifts all
subsequent elements one to the left, which makes it O(n). <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.swap_remove"><code>Vec::swap_remove</code></a>
replaces an element at a particular index with the final element, which does
not preserve ordering, but is O(1).</p>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.retain"><code>Vec::retain</code></a> efficiently removes multiple items from a <code>Vec</code>. There is an
equivalent method for other collection types such as <code>String</code>, <code>HashSet</code>, and
<code>HashMap</code>.</p>
<h2 id="option-and-result"><a class="header" href="#option-and-result"><code>Option</code> and <code>Result</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or"><code>Option::ok_or</code></a> converts an <code>Option</code> into a <code>Result</code>, and is passed an <code>err</code>
parameter that is used if the <code>Option</code> value is <code>None</code>. <code>err</code> is computed
eagerly. If its computation is expensive, you should instead use
<a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or_else"><code>Option::ok_or_else</code></a>, which computes the error value lazily via a closure.
For example, this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn expensive() {}
</span><span class="boring">let o: Option&lt;u32&gt; = None;
</span>let r = o.ok_or(expensive()); // always evaluates `expensive()`
<span class="boring">}</span></code></pre></pre>
<p>should be changed to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn expensive() {}
</span><span class="boring">let o: Option&lt;u32&gt; = None;
</span>let r = o.ok_or_else(|| expensive()); // evaluates `expensive()` only when needed
<span class="boring">}</span></code></pre></pre>
<p><a href="https://github.com/rust-lang/rust/pull/50051/commits/5070dea2366104fb0b5c344ce7f2a5cf8af176b0"><strong>Example</strong></a>.</p>
<p>There are similar alternatives for <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.map_or"><code>Option::map_or</code></a>, <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.unwrap_or"><code>Option::unwrap_or</code></a>,
<a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.or"><code>Result::or</code></a>, <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.map_or"><code>Result::map_or</code></a>, and <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.unwrap_or"><code>Result::unwrap_or</code></a>.</p>
<h2 id="rcarc-1"><a class="header" href="#rcarc-1"><code>Rc</code>/<code>Arc</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/rc/struct.Rc.html#method.make_mut"><code>Rc::make_mut</code></a>/<a href="https://doc.rust-lang.org/std/sync/struct.Arc.html#method.make_mut"><code>Arc::make_mut</code></a> provide clone-on-write semantics. They make
a mutable reference to an <code>Rc</code>/<code>Arc</code>. If the refcount is greater than one, they
will <code>clone</code> the inner value to ensure unique ownership; otherwise, they will
modify the original value. They are not needed often, but they can be extremely
useful on occasion.
<a href="https://github.com/rust-lang/rust/pull/65198/commits/3832a634d3aa6a7c60448906e6656a22f7e35628"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65198/commits/75e0078a1703448a19e25eac85daaa5a4e6e68ac"><strong>Example 2</strong></a>.</p>
<h2 id="mutex-rwlock-condvar-and-once"><a class="header" href="#mutex-rwlock-condvar-and-once"><code>Mutex</code>, <code>RwLock</code>, <code>Condvar</code>, and <code>Once</code></a></h2>
<p>The <a href="https://crates.io/crates/parking_lot"><code>parking_lot</code></a> crate provides alternative implementations of these
synchronization types. The APIs and semantics of the <code>parking_lot</code> types are
similar but not identical to those of the equivalent types in the standard
library.</p>
<p>The <code>parking_lot</code> versions used to be reliably smaller, faster, and more
flexible than those in the standard library, but the standard library versions
have greatly improved on some platforms. So you should measure before switching
to <code>parking_lot</code>.</p>
<p>If you decide to universally use the <code>parking_lot</code> types it is easy to
accidentally use the standard library equivalents in some places. You can <a href="linting.html#disallowing-types">use
Clippy</a> to avoid this problem.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iterators"><a class="header" href="#iterators">Iterators</a></h1>
<h2 id="collect-and-extend"><a class="header" href="#collect-and-extend"><code>collect</code> and <code>extend</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect"><code>Iterator::collect</code></a> converts an iterator into a collection such as <code>Vec</code>,
which typically requires an allocation. You should avoid calling <code>collect</code> if
the collection is then only iterated over again.</p>
<p>For this reason, it is often better to return an iterator type like <code>impl Iterator&lt;Item=T&gt;</code> from a function than a <code>Vec&lt;T&gt;</code>. Note that sometimes
additional lifetimes are required on these return types, as <a href="https://blog.katona.me/2019/12/29/Rust-Lifetimes-and-Iterators/">this blog post</a>
explains.
<a href="https://github.com/rust-lang/rust/pull/77990/commits/660d8a6550a126797aa66a417137e39a5639451b"><strong>Example</strong></a>.</p>
<p>Similarly, you can use <a href="https://doc.rust-lang.org/std/iter/trait.Extend.html#tymethod.extend"><code>extend</code></a> to extend an existing collection (such as a
<code>Vec</code>) with an iterator, rather than collecting the iterator into a <code>Vec</code> and
then using <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.append"><code>append</code></a>.</p>
<p>Finally, when you write an iterator it is often worth implementing the
<a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.size_hint"><code>Iterator::size_hint</code></a> or <a href="https://doc.rust-lang.org/std/iter/trait.ExactSizeIterator.html#method.len"><code>ExactSizeIterator::len</code></a> method, if possible.
<code>collect</code> and <code>extend</code> calls that use the iterator may then do fewer
allocations, because they have advance information about the number of elements
yielded by the iterator.</p>
<h2 id="chaining"><a class="header" href="#chaining">Chaining</a></h2>
<p><a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.chain"><code>chain</code></a> can be very convenient, but it can also be slower than a single
iterator. It may be worth avoiding for hot iterators, if possible.
<a href="https://github.com/rust-lang/rust/pull/64801/commits/5ca99b750e455e9b5e13e83d0d7886486231e48a"><strong>Example</strong></a>.</p>
<p>Similarly, <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map"><code>filter_map</code></a> may be faster than using <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter"><code>filter</code></a> followed by
<a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map"><code>map</code></a>.</p>
<h2 id="chunks"><a class="header" href="#chunks">Chunks</a></h2>
<p>When a chunking iterator is required and the chunk size is known to exactly
divide the slice length, use the faster <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.chunks_exact"><code>slice::chunks_exact</code></a> instead of <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.chunks"><code>slice::chunks</code></a>.</p>
<p>When the chunk size is not known to exactly divide the slice length, it can
still be faster to use <code>slice::chunks_exact</code> in combination with either
<a href="https://doc.rust-lang.org/stable/std/slice/struct.ChunksExact.html#method.remainder"><code>ChunksExact::remainder</code></a> or manual handling of excess elements.
<a href="https://github.com/johannesvollmer/exrs/pull/173/files"><strong>Example 1</strong></a>,
<a href="https://github.com/johannesvollmer/exrs/pull/175/files"><strong>Example 2</strong></a>.</p>
<p>The same is true for related iterators:</p>
<ul>
<li><a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.rchunks"><code>slice::rchunks</code></a>, <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.rchunks_exact"><code>slice::rchunks_exact</code></a>, and <a href="https://doc.rust-lang.org/stable/std/slice/struct.RChunksExact.html#method.remainder"><code>RChunksExact::remainder</code></a>;</li>
<li><a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.chunks_mut"><code>slice::chunks_mut</code></a>, <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.chunks_exact_mut"><code>slice::chunks_exact_mut</code></a>, and <a href="https://doc.rust-lang.org/stable/std/slice/struct.ChunksExactMut.html#method.into_remainder"><code>ChunksExactMut::into_remainder</code></a>;</li>
<li><a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.rchunks_mut"><code>slice::rchunks_mut</code></a>, <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.rchunks_exact_mut"><code>slice::rchunks_exact_mut</code></a>, and <a href="https://doc.rust-lang.org/stable/std/slice/struct.RChunksExactMut.html#method.into_remainder"><code>RChunksExactMut::into_remainder</code></a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bounds-checks"><a class="header" href="#bounds-checks">Bounds Checks</a></h1>
<p>By default, accesses to container types such as slices and vectors involve
bounds checks in Rust. These can affect performance, e.g. within hot loops,
though less often than you might expect.</p>
<p>There are several safe ways to change code so that the compiler knows about
container lengths and can optimize away bounds checks.</p>
<ul>
<li>Replace direct element accesses in a loop by using iteration.</li>
<li>Instead of indexing into a <code>Vec</code> within a loop, make a slice of the <code>Vec</code>
before the loop and then index into the slice within the loop.</li>
<li>Add assertions on the ranges of index variables.
<a href="https://github.com/rust-random/rand/pull/960/commits/de9dfdd86851032d942eb583d8d438e06085867b"><strong>Example 1</strong></a>,
<a href="https://github.com/image-rs/jpeg-decoder/pull/167/files"><strong>Example 2</strong></a>.</li>
</ul>
<p>Getting these to work can be tricky. The <a href="https://github.com/Shnatsel/bounds-check-cookbook/">Bounds Check Cookbook</a> goes into more
detail on this topic.</p>
<p>As a last resort, there are the unsafe methods <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked"><code>get_unchecked</code></a> and
<a href="https://doc.rust-lang.org/std/primitive.slice.html#method.get_unchecked_mut"><code>get_unchecked_mut</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="io"><a class="header" href="#io">I/O</a></h1>
<h2 id="locking"><a class="header" href="#locking">Locking</a></h2>
<p>Rust’s <a href="https://doc.rust-lang.org/std/macro.print.html"><code>print!</code></a> and <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a> macros lock stdout on every call. If you
have repeated calls to these macros it may be better to lock stdout manually.</p>
<p>For example, change this code:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">let lines = vec!["one", "two", "three"];
</span>for line in lines {
    println!("{}", line);
}
<span class="boring">}</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec!["one", "two", "three"];
</span>use std::io::Write;
let mut stdout = std::io::stdout();
let mut lock = stdout.lock();
for line in lines {
    writeln!(lock, "{}", line)?;
}
// stdout is unlocked when `lock` is dropped
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>stdin and stderr can likewise be locked when doing repeated operations on them.</p>
<h2 id="buffering"><a class="header" href="#buffering">Buffering</a></h2>
<p>Rust file I/O is unbuffered by default. If you have many small and repeated
read or write calls to a file or network socket, use <a href="https://doc.rust-lang.org/std/io/struct.BufReader.html"><code>BufReader</code></a> or
<a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>. They maintain an in-memory buffer for input and output,
minimizing the number of system calls required.</p>
<p>For example, change this unbuffered writer code:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec!["one", "two", "three"];
</span>use std::io::Write;
let mut out = std::fs::File::create("test.txt")?;
for line in lines {
    writeln!(out, "{}", line)?;
}
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec!["one", "two", "three"];
</span>use std::io::{BufWriter, Write};
let mut out = BufWriter::new(std::fs::File::create("test.txt")?);
for line in lines {
    writeln!(out, "{}", line)?;
}
out.flush()?;
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p><a href="https://github.com/rust-lang/rust/pull/93954"><strong>Example 1</strong></a>,
<a href="https://github.com/nnethercote/dhat-rs/pull/22/commits/8c3ae26f1219474ee55c30bc9981e6af2e869be2"><strong>Example 2</strong></a>.</p>
<p>The explicit call to <a href="https://doc.rust-lang.org/std/io/trait.Write.html#tymethod.flush"><code>flush</code></a> is not strictly necessary, as flushing will
happen automatically when <code>out</code> is dropped. However, in that case any error
that occurs on flushing will be ignored, whereas an explicit flush will make
that error explicit.</p>
<p>Forgetting to buffer is more common when writing. Both unbuffered and buffered
writers implement the <a href="https://doc.rust-lang.org/std/io/trait.Write.html"><code>Write</code></a> trait, which means the code for writing
to an unbuffered writer and a buffered writer is much the same. In contrast,
unbuffered readers implement the <a href="https://doc.rust-lang.org/std/io/trait.Read.html"><code>Read</code></a> trait but buffered readers implement
the <a href="https://doc.rust-lang.org/std/io/trait.BufRead.html"><code>BufRead</code></a> trait, which means the code for reading from an unbuffered reader
and a buffered reader is different. For example, it is difficult to read a file
line by line with an unbuffered reader, but it is trivial with a buffered
reader by using <a href="https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_line"><code>BufRead::read_line</code></a> or <a href="https://doc.rust-lang.org/std/io/trait.BufRead.html#method.lines"><code>BufRead::lines</code></a>. For this reason,
it is hard to write an example for readers like the one above for writers,
where the before and after versions are so similar.</p>
<p>Finally, note that buffering also works with stdout, so you might want to
combine manual locking <em>and</em> buffering when making many writes to stdout.</p>
<h2 id="reading-lines-from-a-file-1"><a class="header" href="#reading-lines-from-a-file-1">Reading Lines from a File</a></h2>
<p><a href="heap-allocations.html#reading-lines-from-a-file">This section</a> explains how to avoid excessive allocations when using
<a href="https://doc.rust-lang.org/std/io/trait.BufRead.html"><code>BufRead</code></a> to read a file one line at a time.</p>
<h2 id="reading-input-as-raw-bytes"><a class="header" href="#reading-input-as-raw-bytes">Reading Input as Raw Bytes</a></h2>
<p>The built-in <a href="https://doc.rust-lang.org/std/string/struct.String.html">String</a> type uses UTF-8 internally, which adds a small, but
nonzero overhead caused by UTF-8 validation when you read input into it. If you
just want to process input bytes without worrying about UTF-8 (for example if
you handle ASCII text), you can use <a href="https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_until"><code>BufRead::read_until</code></a>.</p>
<p>There are also dedicated crates for reading <a href="https://github.com/Freaky/rust-linereader">byte-oriented lines of data</a>
and working with <a href="https://github.com/BurntSushi/bstr">byte strings</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logging-and-debugging"><a class="header" href="#logging-and-debugging">Logging and Debugging</a></h1>
<p>Sometimes logging code or debugging code can slow down a program significantly.
Either the logging/debugging code itself is slow, or data collection code that
feeds into logging/debugging code is slow. Make sure that no unnecessary work
is done for logging/debugging purposes when logging/debugging is not enabled.
<a href="https://github.com/rust-lang/rust/pull/50246/commits/2e4f66a86f7baa5644d18bb2adc07a8cd1c7409d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/75133/commits/eeb4b83289e09956e0dda174047729ca87c709fe"><strong>Example 2</strong></a>.</p>
<p>Note that <a href="https://doc.rust-lang.org/std/macro.assert.html"><code>assert!</code></a> calls always run, but <a href="https://doc.rust-lang.org/std/macro.debug_assert.html"><code>debug_assert!</code></a> calls only run in
dev builds. If you have an assertion that is hot but is not necessary for
safety, consider making it a <code>debug_assert!</code>.
<a href="https://github.com/rust-lang/rust/pull/58210/commits/f7ed6e18160bc8fccf27a73c05f3935c9e8f672e"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/90746/commits/580d357b5adef605fc731d295ca53ab8532e26fb"><strong>Example 2</strong></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="wrapper-types"><a class="header" href="#wrapper-types">Wrapper Types</a></h1>
<p>Rust has a variety of “wrapper” types, such as <a href="https://doc.rust-lang.org/std/cell/struct.RefCell.html"><code>RefCell</code></a> and <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>Mutex</code></a>, that
provide special behavior for values. Accessing these values can take a
non-trivial amount of time. If multiple such values are typically accessed
together, it may be better to put them within a single wrapper.</p>
<p>For example, a struct like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::sync::{Arc, Mutex};
</span>struct S {
    x: Arc&lt;Mutex&lt;u32&gt;&gt;,
    y: Arc&lt;Mutex&lt;u32&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>may be better represented like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::sync::{Arc, Mutex};
</span>struct S {
    xy: Arc&lt;Mutex&lt;(u32, u32)&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Whether or not this helps performance will depend on the exact access patterns
of the values.
<a href="https://github.com/rust-lang/rust/pull/68694/commits/7426853ba255940b880f2e7f8026d60b94b42404"><strong>Example</strong></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="machine-code"><a class="header" href="#machine-code">Machine Code</a></h1>
<p>When you have a small piece of very hot code it may be worth inspecting the
generated machine code to see if it has any inefficiencies, such as removable
<a href="bounds-checks.html">bounds checks</a>. The <a href="https://godbolt.org/">Compiler Explorer</a> website is an excellent resource when
doing this on small snippets. <a href="https://github.com/pacak/cargo-show-asm"><code>cargo-show-asm</code></a> is an alternative tool that
can be used on full Rust projects.</p>
<p>Relatedly, the <a href="https://doc.rust-lang.org/core/arch/index.html"><code>core::arch</code></a> module provides access to architecture-specific
intrinsics, many of which relate to SIMD instructions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parallelism"><a class="header" href="#parallelism">Parallelism</a></h1>
<p>Rust provides excellent support for safe parallel programming, which can lead
to large performance improvements. There are a variety of ways to introduce
parallelism into a program and the best way for any program will depend greatly
on its design.</p>
<p>An in-depth treatment of parallelism is beyond the scope of this book. If you
are interested in this topic, the documentation for the <a href="https://crates.io/crates/rayon"><code>rayon</code></a> and
<a href="https://crates.io/crates/crossbeam"><code>crossbeam</code></a> crates is a good place to start.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-tips"><a class="header" href="#general-tips">General Tips</a></h1>
<p>The previous sections of this book have discussed Rust-specific techniques.
This section gives a brief overview of some general performance principles.</p>
<p>As long as the obvious pitfalls are avoided (e.g. <a href="build-configuration.html">using non-release builds</a>),
Rust code generally is fast and uses little memory. Especially if you are used
to dynamically-typed languages such as Python and Ruby, or statically-types
languages with a garbage collector such as Java and C#.</p>
<p>Optimized code is often more complex and takes more effort to write than
unoptimized code. For this reason, it is only worth optimizing hot code.</p>
<p>The biggest performance improvements often come from changes to algorithms or
data structures, rather than low-level optimizations.
<a href="https://github.com/rust-lang/rust/pull/53383/commits/5745597e6195fe0591737f242d02350001b6c590"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/54318/commits/154be2c98cf348de080ce951df3f73649e8bb1a6"><strong>Example 2</strong></a>.</p>
<p>Writing code that works well with modern hardware is not always easy, but worth
striving for. For example, try to minimize cache misses and branch
mispredictions, where possible.</p>
<p>Most optimizations result in small speedups. Although no single small speedup
is noticeable, they really add up if you can do enough of them.</p>
<p>Different profilers have different strengths. It is good to use more than one.</p>
<p>When profiling indicates that a function is hot, there are two common ways to
speed things up: (a) make the function faster, and/or (b) avoid calling it as
much.</p>
<p>It is often easier to eliminate silly slowdowns than it is to introduce clever
speedups.</p>
<p>Avoid computing things unless necessary. Lazy/on-demand computations are
often a win.
<a href="https://github.com/rust-lang/rust/pull/36592/commits/80a44779f7a211e075da9ed0ff2763afa00f43dc"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50339/commits/989815d5670826078d9984a3515eeb68235a4687"><strong>Example 2</strong></a>.</p>
<p>Complex general cases can often be avoided by optimistically checking for
common special cases that are simpler.
<a href="https://github.com/rust-lang/rust/pull/68790/commits/d62b6f204733d255a3e943388ba99f14b053bf4a"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/53733/commits/130e55665f8c9f078dec67a3e92467853f400250"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65260/commits/59e41edcc15ed07de604c61876ea091900f73649"><strong>Example 3</strong></a>.
In particular, specially handling collections with 0, 1, or 2 elements is often
a win when small sizes dominate.
<a href="https://github.com/rust-lang/rust/pull/50932/commits/2ff632484cd8c2e3b123fbf52d9dd39b54a94505"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64627/commits/acf7d4dcdba4046917c61aab141c1dec25669ce9"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64949/commits/14192607d38f5501c75abea7a4a0e46349df5b5f"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64949/commits/d1a7bb36ad0a5932384eac03d3fb834efc0317e5"><strong>Example 4</strong></a>.</p>
<p>Similarly, when dealing with repetitive data, it is often possible to use a
simple form of data compression, by using a compact representation for common
values and then having a fallback to a secondary table for unusual values.
<a href="https://github.com/rust-lang/rust/pull/54420/commits/b2f25e3c38ff29eebe6c8ce69b8c69243faa440d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/59693/commits/fd7f605365b27bfdd3cd6763124e81bddd61dd28"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65750/commits/eea6f23a0ed67fd8c6b8e1b02cda3628fee56b2f"><strong>Example 3</strong></a>.</p>
<p>When code deals with multiple cases, measure case frequencies and handle the
most common ones first.</p>
<p>When dealing with lookups that involve high locality, it can be a win to put a
small cache in front of a data structure.</p>
<p>Optimized code often has a non-obvious structure, which means that explanatory
comments are valuable, particularly those that reference profiling
measurements. A comment like “99% of the time this vector has 0 or 1 elements,
so handle those cases first” can be illuminating.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compile-times"><a class="header" href="#compile-times">Compile Times</a></h1>
<p>Although this book is primarily about improving the performance of Rust
programs, this section is about reducing the compile times of Rust programs,
because that is a related topic of interest to many people.</p>
<p>The <a href="build-configuration.html#minimizing-compile-times">Minimizing Compile Times</a> section discussed ways to reduce compile times
via build configuration choices. The rest of this section discusses ways to
reduce compile times that require modifying your program’s code.</p>
<h2 id="visualization"><a class="header" href="#visualization">Visualization</a></h2>
<p>Cargo has a feature that lets you visualize compilation of your
program. Build with this command:</p>
<pre><code class="language-text">cargo build --timings
</code></pre>
<p>On completion it will print the name of an HTML file. Open that file in a web
browser. It contains a <a href="https://en.wikipedia.org/wiki/Gantt_chart">Gantt chart</a> that shows the dependencies between the
various crates in your program. This shows how much parallelism there is in
your crate graph, which can indicate if any large crates that serialize
compilation should be broken up. See <a href="https://doc.rust-lang.org/nightly/cargo/reference/timings.html">the documentation</a> for more
details on how to read the graphs.</p>
<h2 id="llvm-ir"><a class="header" href="#llvm-ir">LLVM IR</a></h2>
<p>The Rust compiler uses <a href="https://llvm.org/">LLVM</a> for its back-end. LLVM’s execution can be a large
part of compile times, especially when the Rust compiler’s front end generates
a lot of <a href="https://en.wikipedia.org/wiki/Intermediate_representation">IR</a> which takes LLVM a long time to optimize.</p>
<p>These problems can be diagnosed with <a href="https://github.com/dtolnay/cargo-llvm-lines/"><code>cargo llvm-lines</code></a>, which shows which
Rust functions cause the most LLVM IR to be generated. Generic functions are
often the most important ones, because they can be instantiated dozens or even
hundreds of times in large programs.</p>
<p>If a generic function causes IR bloat, there are several ways to fix it. The
simplest is to just make the function smaller.
<a href="https://github.com/rust-lang/rust/pull/72166/commits/5a0ac0552e05c079f252482cfcdaab3c4b39d614"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/91246/commits/f3bda74d363a060ade5e5caeb654ba59bfed51a4"><strong>Example 2</strong></a>.</p>
<p>Another way is to move the non-generic parts of the function into a separate,
non-generic function, which will only be instantiated once. Whether this is
possible will depend on the details of the generic function. When it is
possible, the non-generic function can often be written neatly as an inner
function within the generic function, as shown by the code for
<a href="https://doc.rust-lang.org/std/fs/fn.read.html"><code>std::fs::read</code></a>:</p>
<pre><code class="language-rust ignore">pub fn read&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    fn inner(path: &amp;Path) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
        let mut file = File::open(path)?;
        let size = file.metadata().map(|m| m.len()).unwrap_or(0);
        let mut bytes = Vec::with_capacity(size as usize);
        io::default_read_to_end(&amp;mut file, &amp;mut bytes)?;
        Ok(bytes)
    }
    inner(path.as_ref())
}</code></pre>
<p><a href="https://github.com/rust-lang/rust/pull/72013/commits/68b75033ad78d88872450a81745cacfc11e58178"><strong>Example</strong></a>.</p>
<p>Sometimes common utility functions like <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.map"><code>Option::map</code></a> and <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err"><code>Result::map_err</code></a>
are instantiated many times. Replacing them with equivalent <code>match</code> expressions
can help compile times.</p>
<p>The effects of these sorts of changes on compile times will usually be small,
though occasionally they can be large.
<a href="https://github.com/servo/servo/issues/26585"><strong>Example</strong></a>.</p>
<p>Such changes can also reduce binary size.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
