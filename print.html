<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js rust">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Rust Performance Book</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "rust";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="benchmarking.html"><strong aria-hidden="true">2.</strong> Benchmarking</a></li><li class="chapter-item expanded "><a href="build-configuration.html"><strong aria-hidden="true">3.</strong> Build Configuration</a></li><li class="chapter-item expanded "><a href="linting.html"><strong aria-hidden="true">4.</strong> Linting</a></li><li class="chapter-item expanded "><a href="profiling.html"><strong aria-hidden="true">5.</strong> Profiling</a></li><li class="chapter-item expanded "><a href="inlining.html"><strong aria-hidden="true">6.</strong> Inlining</a></li><li class="chapter-item expanded "><a href="hashing.html"><strong aria-hidden="true">7.</strong> Hashing</a></li><li class="chapter-item expanded "><a href="heap-allocations.html"><strong aria-hidden="true">8.</strong> Heap Allocations</a></li><li class="chapter-item expanded "><a href="type-sizes.html"><strong aria-hidden="true">9.</strong> Type Sizes</a></li><li class="chapter-item expanded "><a href="standard-library-types.html"><strong aria-hidden="true">10.</strong> Standard Library Types</a></li><li class="chapter-item expanded "><a href="iterators.html"><strong aria-hidden="true">11.</strong> Iterators</a></li><li class="chapter-item expanded "><a href="io.html"><strong aria-hidden="true">12.</strong> I/O</a></li><li class="chapter-item expanded "><a href="logging-and-debugging.html"><strong aria-hidden="true">13.</strong> Logging and Debugging</a></li><li class="chapter-item expanded "><a href="wrapper-types.html"><strong aria-hidden="true">14.</strong> Wrapper Types</a></li><li class="chapter-item expanded "><a href="machine-code.html"><strong aria-hidden="true">15.</strong> Machine Code</a></li><li class="chapter-item expanded "><a href="parallelism.html"><strong aria-hidden="true">16.</strong> Parallelism</a></li><li class="chapter-item expanded "><a href="general-tips.html"><strong aria-hidden="true">17.</strong> General Tips</a></li><li class="chapter-item expanded "><a href="compile-times.html"><strong aria-hidden="true">18.</strong> Compile Times</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">The Rust Performance Book</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/nnethercote/perf-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p>Performance is important for many Rust programs. </p>
<p>This book contains many techniques that can improve the performance—speed and
memory usage—of Rust programs. The <a href="compile-times.html">Compile Times</a> section also contains some
techniques that will improve the compile times of Rust programs. Some of the
book’s techniques only require changing build configurations, but many require
changing code.</p>
<p>Some of the techniques within are entirely Rust-specific, and some involve
ideas that can be applied (often with modifications) to programs written in
other languages. The <a href="general-tips.html">General Tips</a> section also includes some general
principles that apply to any programming language. Nonetheless, this book is
mostly about the performance of Rust programs and is no substitute for a
general purpose guide to profiling and optimization.</p>
<p>The book also focuses on techniques that are practical and proven: many are
accompanied by links to pull requests or other resources that show how the
technique was used on a real-world Rust program.</p>
<p>This book is aimed at intermediate and advanced Rust users. Beginner Rust users
have more than enough to learn and these techniques are likely to be an
unhelpful distraction to them.</p>
<h1><a class="header" href="#benchmarking" id="benchmarking">Benchmarking</a></h1>
<p>When optimizing a program, you need a way to reliably answer the question “did
this change speed things up?” This process is sometimes called benchmarking.
Benchmarking is a complex topic and a thorough coverage is beyond the scope of
this book, but here are the basics.</p>
<p>First, you need workloads to measure. Ideally, you would have a variety of
workloads that represent realistic usage of your program. Workloads using
real-world inputs are best, but <a href="https://stackoverflow.com/questions/2842695/what-is-microbenchmarking">microbenchmarks</a> and <a href="https://en.wikipedia.org/wiki/Stress_testing_(software)">stress tests</a> can be
useful in moderation.</p>
<p>Second, you need a way to run the workloads, which will also dictate the
metrics used. Rust’s built-in <a href="https://doc.rust-lang.org/1.7.0/book/benchmark-tests.html">benchmark tests</a> are a simple starting point.
<a href="https://github.com/bheisler/criterion.rs">Criterion</a> is a more sophisticated alternative. Custom benchmarking harnesses
are also possible. For example, <a href="https://github.com/rust-lang/rustc-perf/">rustc-perf</a> is the harness used to benchmark
the Rust compiler.</p>
<p>When it comes to metrics, there are many choices, and the right one(s) will
depend on the nature of the program being benchmarked. For example, metrics
that make sense for a batch program might not make sense for an interactive
program. Wall-time is an obvious choice in many cases because it corresponds to
what users perceive. However, it can suffer from high variance. In particular,
tiny changes in memory layout can cause significant but ephemeral performance
fluctuations. Therefore, other metrics with lower variance (such as cycles or
instruction counts) may be a reasonable alternative.</p>
<p>Summarizing measurements from multiple workloads is also a challenge, and there
are a variety of ways to do it, with no single method being obviously best.</p>
<p>Good benchmarking is hard. Having said that, do not stress too much about
having a perfect benchmarking setup, particularly when you start optimizing a
program. A mediocre setup is far better than no setup. Keep an open mind about
what you are measuring, and over time you can make benchmarking improvements as
you learn about the performance characteristics of your program.</p>
<h1><a class="header" href="#build-configuration" id="build-configuration">Build Configuration</a></h1>
<p>The right build configuration will maximize the performance of your Rust
program without any changes to its code.</p>
<h2><a class="header" href="#release-builds" id="release-builds">Release Builds</a></h2>
<p>The single most important Rust performance tip is simple but <a href="https://users.rust-lang.org/t/why-my-rust-program-is-so-slow/47764/5">easy to
overlook</a>: make sure you are using a release build rather than a debug build
when you want high performance. This is most often done by specifying the
<code>--release</code> flag to Cargo.</p>
<p>A release build typically runs <em>much</em> faster than a debug build. 10-100x
speedups over debug builds are common!</p>
<p>Debug builds are the default. They are produced if you run <code>cargo build</code>,
<code>cargo run</code>, or <code>rustc</code> without any additional options. Debug builds are good
for debugging, but are not optimized.</p>
<p>Consider the following final line of output from a <code>cargo build</code> run.</p>
<pre><code class="language-text">Finished dev [unoptimized + debuginfo] target(s) in 29.80s
</code></pre>
<p>The <code>[unoptimized + debuginfo]</code> indicates that a debug build has been produced.
The compiled code will be placed in the <code>target/debug/</code> directory. <code>cargo run</code>
will run the debug build.</p>
<p>Release builds are more optimized than debug builds. They also omit some
checks, such as debug assertions and integer overflow checks. Produce one with
<code>cargo build --release</code>, <code>cargo run --release</code>, or <code>rustc -O</code>. (Alternatively,
<code>rustc</code> has multiple other options for optimized builds, such as <code>-C opt-level</code>.) This will typically take longer than a debug build because of the
additional optimizations.</p>
<p>Consider the following final line of output from a <code>cargo build --release</code> run.</p>
<pre><code class="language-text">Finished release [optimized] target(s) in 1m 01s
</code></pre>
<p>The <code>[optimized]</code> indicates that a release build has been produced. The
compiled code will be placed in the <code>target/release/</code> directory. <code>cargo run --release</code> will run the release build.</p>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html">Cargo profile documentation</a> for more details about the differences
between debug builds (which use the <code>dev</code> profile) and release builds (which
use the <code>release</code> profile).</p>
<h2><a class="header" href="#link-time-optimization" id="link-time-optimization">Link-time Optimization</a></h2>
<p>Link-time optimization (LTO) is a whole-program optimization technique that can
improve runtime performance by 10-20% or more, at the cost of increased build
times. For any individual Rust program it is easy to see if the runtime versus
compile-time trade-off is worthwhile.</p>
<p>The simplest way to try LTO is to add the following lines to the <code>Cargo.toml</code>
file and do a release build.</p>
<pre><code class="language-toml">[profile.release]
lto = true
</code></pre>
<p>This will result in “fat” LTO, which optimizes across all crates in the
dependency graph.</p>
<p>Alternatively, use <code>lto = &quot;thin&quot;</code> in <code>Cargo.toml</code> to use “thin” LTO, which is a
less aggressive form of LTO that often works as well as “fat” LTO without
increasing build times as much.</p>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#lto">Cargo LTO documentation</a> for more details about the <code>lto</code> setting, and
about enabling specific settings for different profiles.</p>
<h2><a class="header" href="#codegen-units" id="codegen-units">Codegen Units</a></h2>
<p>The Rust compiler splits your crate into multiple <a href="https://doc.rust-lang.org/rustc/codegen-options/index.html#codegen-units">codegen units</a> to
parallelize (and thus speed up) compilation. However, this might cause it to
miss some potential optimizations. If you want to potentially improve runtime
performance at the cost of larger compile time, you can set the number of units
to one:</p>
<pre><code class="language-toml">[profile.release]
codegen-units = 1
</code></pre>
<p><a href="https://likebike.com/posts/How_To_Write_Fast_Rust_Code.html#emit-asm"><strong>Example</strong></a>.</p>
<p>Be wary that the codegen unit count is a heuristic and thus a smaller count can
actually result in a slower program.</p>
<h2><a class="header" href="#using-cpu-specific-instructions" id="using-cpu-specific-instructions">Using CPU Specific Instructions</a></h2>
<p>If you do not care that much about the compatibility of your binary on older
(or other types of) processors, you can tell the compiler to generate the
newest (and potentially fastest) instructions specific to a <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#target-cpu">certain CPU
architecture</a>.</p>
<p>For example, if you pass <code>-C target-cpu=native</code> to rustc, it will use the best
instructions for your current CPU:</p>
<pre><code class="language-bash">$ RUSTFLAGS=&quot;-C target-cpu=native&quot; cargo build --release
</code></pre>
<p>This can have a large effect, especially if the compiler finds vectorization
opportunities in your code.</p>
<h2><a class="header" href="#abort-on-panic" id="abort-on-panic">Abort on <code>panic!</code></a></h2>
<p>If you do not need to catch or unwind panics, you can tell the compiler to
simply abort on panics. This might reduce binary size and increase performance
slightly:</p>
<pre><code class="language-toml">[profile.release]
panic = &quot;abort&quot;
</code></pre>
<h2><a class="header" href="#profile-guided-optimization" id="profile-guided-optimization">Profile-guided Optimization</a></h2>
<p>Profile-guided optimization (PGO) is a compilation model where you compile
your program, run it on sample data while collecting profiling data, and then
use that profiling data to guide a second compilation of the program.
<a href="https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html"><strong>Example</strong></a>.</p>
<p>It is an advanced technique that takes some effort to set up, but is worthwhile
in some cases. See the <a href="https://doc.rust-lang.org/rustc/profile-guided-optimization.html">rustc PGO documentation</a> for details.</p>
<h1><a class="header" href="#linting" id="linting">Linting</a></h1>
<p><a href="https://github.com/rust-lang/rust-clippy">Clippy</a> is a collection of lints to catch common mistakes in Rust code. It is
an excellent tool to run on Rust code in general. It can also help with
performance, because a number of the lints relate to code patterns that can
cause sub-optimal performance.</p>
<p>Once installed, it is easy to run:</p>
<pre><code class="language-text">cargo clippy
</code></pre>
<p>The full list of performance lints can be seen by visiting the <a href="https://rust-lang.github.io/rust-clippy/master/">lint list</a> and
deselecting all the lint groups except for “Perf”.</p>
<p>As well as making the code faster, the performance lint suggestions usually
result in code that is simpler and more idiomatic, so they are worth following
even for code that is not hot.</p>
<h1><a class="header" href="#profiling" id="profiling">Profiling</a></h1>
<p>When optimizing a program, you also need a way to determine which parts of the
program are hot and worth modifying. This is best done via profiling.</p>
<h2><a class="header" href="#profilers" id="profilers">Profilers</a></h2>
<p>There are many different profilers available, each with their strengths and
weaknesses. The following is an incomplete list of profilers that have been
used successfully on Rust programs.</p>
<ul>
<li><a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> is a general-purpose profiler that uses hardware performance counters.
<a href="https://github.com/KDAB/hotspot">Hotspot</a> and <a href="https://profiler.firefox.com/">Firefox Profiler</a> are good for viewing data recorded by perf.</li>
<li><a href="https://www.valgrind.org/docs/manual/cg-manual.html">Cachegrind</a> &amp; <a href="https://www.valgrind.org/docs/manual/cl-manual.html">Callgrind</a> give global, per-function, and per-source-line
instruction counts and simulated cache and branch prediction data.</li>
<li><a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> is good for finding which parts of the code are causing a lot of
allocations, and for giving insight into peak memory usage. <a href="https://github.com/KDE/heaptrack">heaptrack</a> is
another heap profiling tool.</li>
<li><a href="https://github.com/nnethercote/counts/"><code>counts</code></a> supports ad hoc profiling, which combines the use of <code>eprintln!</code>
statement with frequency-based post-processing, which is good for getting
domain-specific insights into parts of your code.</li>
<li><a href="https://github.com/plasma-umass/coz">Coz</a> performs <em>causal profiling</em> to measure optimization potential. It has
Rust support via <a href="https://github.com/plasma-umass/coz/tree/master/rust">coz-rs</a>.</li>
<li><a href="https://github.com/flamegraph-rs/flamegraph">flamegraph</a> is a Cargo command that uses <code>perf</code>/<code>DTrace</code> to profile your
code and then displays the results in a flame graph.</li>
</ul>
<h2><a class="header" href="#debug-info" id="debug-info">Debug Info</a></h2>
<p>To profile a release build effectively you might need to enable source line
debug info. To do this, add the following lines to your <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[profile.release]
debug = 1
</code></pre>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#debug">Cargo documentation</a> for more details about the <code>debug</code> setting.</p>
<h2><a class="header" href="#symbol-demangling" id="symbol-demangling">Symbol Demangling</a></h2>
<p>Rust uses a mangling scheme to encode function names in compiled code. If a
profiler is unaware of this scheme, its output may contain symbol names like
<code>_ZN3foo3barE</code> or <code>_ZN28_$u7b$$u7b$closure$u7d$$u7d$E</code> or
<code>_ZN88_$LT$core..result..Result$LT$$u21$$C$$u20$E$GT$$u20$as$u20$std..process..Termination$GT$6report17hfc41d0da4a40b3e8E</code>.
Names like these can be manually demangled using <a href="https://crates.io/crates/rustfilt"><code>rustfilt</code></a>.</p>
<h1><a class="header" href="#inlining" id="inlining">Inlining</a></h1>
<p>Entry to and exit from hot, uninlined functions often accounts for a
non-trivial fraction of execution time. Inlining these functions can provide
small but easy speed wins. </p>
<p>There are four inline attributes that can be used on Rust functions.</p>
<ul>
<li><strong>None</strong>. The compiler will decide itself if the function should be inlined.
This will depend on the optimization level, the size of the function, etc. If
you are not using link-time optimization, functions will never be inlined
across crates.</li>
<li><strong><code>#[inline]</code></strong>. This suggests that the function should be inlined, including
across crate boundaries.</li>
<li><strong><code>#[inline(always)]</code></strong>. This strongly suggests that the function should be
inlined, including across crate boundaries.</li>
<li><strong><code>#[inline(never)]</code></strong>. This strongly suggests that the function should not
be inlined.</li>
</ul>
<p>Inline attributes do not guarantee that a function is inlined or not inlined,
but in practice, <code>#[inline(always)]</code> will cause inlining in all but the most
exceptional cases.</p>
<h2><a class="header" href="#simple-cases" id="simple-cases">Simple Cases</a></h2>
<p>The best candidates for inlining are (a) functions that are very small, or (b)
functions that have a single call site. The compiler will often inline these
functions itself even without an inline attribute. But the compiler cannot
always make the best choices, so attributes are sometimes needed.
<a href="https://github.com/rust-lang/rust/pull/37083/commits/6a4bb35b70862f33ac2491ffe6c55fb210c8490d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50407/commits/e740b97be699c9445b8a1a7af6348ca2d4c460ce"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50564/commits/77c40f8c6f8cc472f6438f7724d60bf3b7718a0c"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/57719/commits/92fd6f9d30d0b6b4ecbcf01534809fb66393f139"><strong>Example 4</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/69256/commits/e761f3af904b3c275bdebc73bb29ffc45384945d"><strong>Example 5</strong></a>.</p>
<p>Cachegrind is a good profiler for determining if a function is inlined. When
looking at Cachegrind’s output, you can tell that a function has been inlined
if (and only if) its first and last lines are <em>not</em> marked with event counts.
For example:</p>
<pre><code class="language-text">      .  #[inline(always)]
      .  fn inlined(x: u32, y: u32) -&gt; u32 {
700,000      eprintln!(&quot;inlined: {} + {}&quot;, x, y);
200,000      x + y
      .  }
      .  
      .  #[inline(never)]
400,000  fn not_inlined(x: u32, y: u32) -&gt; u32 {
700,000      eprintln!(&quot;not_inlined: {} + {}&quot;, x, y);
200,000      x + y
200,000  }
</code></pre>
<p>You should measure again after adding inline attributes, because the effects
can be unpredictable. Sometimes it has no effect because a nearby function that
was previously inlined no longer is. Sometimes it slows the code down. Inlining
can also affect compile times, especially cross-crate inlining which involves
duplicating internal representations of the functions.</p>
<h2><a class="header" href="#harder-cases" id="harder-cases">Harder Cases</a></h2>
<p>Sometimes you have a function that is large and has multiple call sites, but
only one call site is hot. You would like to inline the hot call site for
speed, but not inline the cold call sites to avoid unnecessary code bloat. The
way to handle this is to split the function always-inlined and never-inlined
variants, with the latter calling the former.</p>
<p>For example, this function:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn one() {};
</span><span class="boring">fn two() {};
</span><span class="boring">fn three() {};
</span>fn my_function() {
    one();
    two();
    three();
}
<span class="boring">}
</span></code></pre></pre>
<p>Would become these two functions:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn one() {};
</span><span class="boring">fn two() {};
</span><span class="boring">fn three() {};
</span>// Use this at the hot call site.
#[inline(always)]
fn inlined_my_function() {
    one();
    two();
    three();
}

// Use this at the cold call sites.
#[inline(never)]
fn uninlined_my_function() {
    inlined_my_function();
}
<span class="boring">}
</span></code></pre></pre>
<p><a href="https://github.com/rust-lang/rust/pull/53513/commits/b73843f9422fb487b2d26ac2d65f79f73a4c9ae3"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64420/commits/a2261ad66400c3145f96ebff0d9b75e910fa89dd"><strong>Example 2</strong></a>.</p>
<h1><a class="header" href="#hashing" id="hashing">Hashing</a></h1>
<p><code>HashSet</code> and <code>HashMap</code> are two widely-used types. The default hashing
algorithm is not specified, but at the time of writing the default is an
algorithm called <a href="https://en.wikipedia.org/wiki/SipHash">SipHash 1-3</a>. This algorithm is high quality—it provides high
protection against collisions—but is relatively slow, particular for short keys
such as integers.</p>
<p>If profiling shows that hashing is hot, and <a href="https://en.wikipedia.org/wiki/Collision_attack">HashDoS attacks</a> are not a concern
for your application, the use of hash tables with faster hash algorithms can
provide large speed wins.</p>
<ul>
<li><a href="https://crates.io/crates/fxhash"><code>fxhash</code></a> provides <code>FxHashSet</code> and <code>FxHashMap</code> types that are drop-in
replacements for <code>HashSet</code> and <code>HashMap</code>. Its hashing algorithm is
low-quality but very fast, especially for integer keys, and has been found to
out-perform all other hash algorithms within rustc.</li>
<li><a href="https://crates.io/crates/fnv"><code>fnv</code></a> provides <code>FnvHashSet</code> and <code>FnvHashMap</code> types. Its hashing algorithm
is higher quality than <code>fxhash</code>‘s but a little slower.</li>
<li><a href="https://crates.io/crates/ahash"><code>ahash</code></a> provides <code>AHashSet</code> and <code>AHashMap</code>. Its hashing algorithm can take
advantage of AES instruction support that is available on some processors.</li>
</ul>
<p>If hashing performance is important in your program, it is worth trying more
than one of these alternatives. For example, the following results were seen in
rustc.</p>
<ul>
<li>The switch from <code>fnv</code> to <code>fxhash</code> gave <a href="https://github.com/rust-lang/rust/pull/37229/commits/00e48affde2d349e3b3bfbd3d0f6afb5d76282a7">speedups of up to 6%</a>.</li>
<li>An attempt to switch from <code>fxhash</code> to <code>ahash</code> resulted in <a href="https://github.com/rust-lang/rust/issues/69153#issuecomment-589504301">slowdowns of
1-4%</a>.</li>
<li>An attempt to switch from <code>fxhash</code> back to the default hasher resulted in
<a href="https://github.com/rust-lang/rust/issues/69153#issuecomment-589338446">slowdowns ranging from 4-84%</a>!</li>
</ul>
<p>If you decide to universally use one of the alternatives, such as
<code>FxHashSet</code>/<code>FxHashMap</code>, it is easy to accidentally use <code>HashSet</code>/<code>HashMap</code> in
some places. The presence of <code>SipHasher13</code> code in profiles is a tell-tale
indicator of this.</p>
<p>Hash function design is a complex topic and is beyond the scope of this book.
The <a href="https://github.com/tkaitchuck/aHash/blob/master/compare/readme.md"><code>ahash</code> documentation</a> has a good discussion. </p>
<h1><a class="header" href="#heap-allocations" id="heap-allocations">Heap Allocations</a></h1>
<p>Heap allocations are moderately expensive. The exact details depend on
allocator is in use, but each allocation (and deallocation) typically involves
acquiring a global lock, doing some non-trivial data structure manipulation,
and possibly executing a system call. Small allocations are not necessarily
cheaper than large allocations. It is worth understanding which Rust data
structures and operations cause allocations, because avoiding them can greatly
improve performance.</p>
<p>The <a href="https://docs.google.com/presentation/d/1q-c7UAyrUlM-eZyTo1pd8SZ0qwA_wYxmPZVOQkoDmH4/">Rust Container Cheat Sheet</a> has visualizations of common Rust types, and
is an excellent companion to the following sections.</p>
<h2><a class="header" href="#profiling-1" id="profiling-1">Profiling</a></h2>
<p>If a general-purpose profiler shows <code>malloc</code>, <code>free</code>, and related functions as
hot, then it is likely worth trying to reduce the allocation rate and/or using
an alternative allocator.</p>
<p><a href="https://www.valgrind.org/docs/manual/dh-manual.html">DHAT</a> is an excellent profiler to use when reducing allocation rates. It
precisely identifies hot allocation sites and their allocation rates. Exact
results will vary, but experience with rustc has shown that reducing allocation
rates by 10 allocations per million instructions executed can have measurable
performance improvements (e.g. ~1%).</p>
<p>Here is some example output from DHAT.</p>
<pre><code class="language-text">AP 1.1/25 (2 children) {
  Total:     54,533,440 bytes (4.02%, 2,714.28/Minstr) in 458,839 blocks (7.72%, 22.84/Minstr), avg size 118.85 bytes, avg lifetime 1,127,259,403.64 instrs (5.61% of program duration)
  At t-gmax: 0 bytes (0%) in 0 blocks (0%), avg size 0 bytes
  At t-end:  0 bytes (0%) in 0 blocks (0%), avg size 0 bytes
  Reads:     15,993,012 bytes (0.29%, 796.02/Minstr), 0.29/byte
  Writes:    20,974,752 bytes (1.03%, 1,043.97/Minstr), 0.38/byte
  Allocated at {
    #1: 0x95CACC9: alloc (alloc.rs:72)
    #2: 0x95CACC9: alloc (alloc.rs:148)
    #3: 0x95CACC9: reserve_internal&lt;syntax::tokenstream::TokenStream,alloc::alloc::Global&gt; (raw_vec.rs:669)
    #4: 0x95CACC9: reserve&lt;syntax::tokenstream::TokenStream,alloc::alloc::Global&gt; (raw_vec.rs:492)
    #5: 0x95CACC9: reserve&lt;syntax::tokenstream::TokenStream&gt; (vec.rs:460)
    #6: 0x95CACC9: push&lt;syntax::tokenstream::TokenStream&gt; (vec.rs:989)
    #7: 0x95CACC9: parse_token_trees_until_close_delim (tokentrees.rs:27)
    #8: 0x95CACC9: syntax::parse::lexer::tokentrees::&lt;impl syntax::parse::lexer::StringReader&lt;'a&gt;&gt;::parse_token_tree (tokentrees.rs:81)
  }
}
</code></pre>
<p>It is beyond the scope of this book to describe everything in this example, but
it should be clear that DHAT gives a wealth of information about allocations,
such as where and how often they happen, how big they are, how long they live
for, and how often they are accessed.</p>
<h2><a class="header" href="#box" id="box"><code>Box</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/boxed/struct.Box.html"><code>Box</code></a> is the simplest heap-allocated type. A <code>Box&lt;T&gt;</code> value is a <code>T</code> value that
is allocated on the heap. </p>
<p>It is sometimes worth boxing one or more fields in a struct or enum fields to
make a type smaller. (See the the <a href="type-sizes.html">Type Sizes</a> chapter for more
about this.)</p>
<p>Other than that, <code>Box</code> is straightforward and does not offer much scope for
optimizations.</p>
<h2><a class="header" href="#rcarc" id="rcarc"><code>Rc</code>/<code>Arc</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a>/<a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>Arc</code></a> are similar to <code>Box</code>, but the value on the heap is accompanied by
two reference counts. They allow value sharing, which can be an effective way
to reduce memory usage.</p>
<p>However, if used for values that are rarely shared, they can increase allocation
rates by heap allocating values that might otherwise not be heap allocated.
<a href="https://github.com/rust-lang/rust/pull/37373/commits/c440a7ae654fb641e68a9ee53b03bf3f7133c2fe"><strong>Example</strong></a>.</p>
<p>Unlike <code>Box</code>, calling <code>clone</code> on an <code>Rc</code>/<code>Arc</code> value does not involve an
allocation. Instead, it merely increments a reference count.</p>
<h2><a class="header" href="#vec" id="vec"><code>Vec</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a> is a heap-allocated type with a great deal of scope for optimizing the
number of allocations, and/or minimizing the amount of wasted space. To do this
requires understanding how its elements are stored.</p>
<p>A <code>Vec</code> contains three words: a length, a capacity, and a (possibly null)
pointer to some number of heap-allocated elements. Even if the <code>Vec</code> itself is
not heap-allocated, the elements (if present) always will be. If elements are
present, the memory holding those elements may be larger than necessary,
providing space for additional future elements. The number of elements present
is the length, and the number of elements that could be held without
reallocating is the capacity. When the vector needs to grow beyond its current
capacity, the elements will be copied into a larger heap allocation, and the
old heap allocation will be freed.</p>
<h3><a class="header" href="#vec-growth" id="vec-growth"><code>Vec</code> growth</a></h3>
<p>A new, empty <code>Vec</code> created by the common means
(<a href="https://doc.rust-lang.org/std/macro.vec.html"><code>vec![]</code></a>
or <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.new"><code>Vec::new</code></a> or <a href="https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default"><code>Vec::default</code></a>) has a length and capacity of zero, and no
heap allocation is required. If you repeatedly push individual elements onto
the end of the <code>Vec</code>, it will periodically reallocate. The growth strategy is
not specified, but at the time of writing it uses a quasi-doubling stategy
resulting in the following capacities: 0, 4, 8, 16, 32, 64, and so on. (It
skips directly from 0 to 4, instead of going via 1 and 2, because this <a href="https://github.com/rust-lang/rust/pull/72227">avoids
many allocations</a> in practice.) As a vector grows, the frequency of
reallocations will decrease exponentially, but the amount of possibly-wasted
excess capacity will increase exponentially.</p>
<p>This growth strategy is typical for growable data structures and reasonable in
the general case, but if you know in advance the likely length of a vector you
can do often do better. If you have a hot vector allocation site (e.g. a hot
<a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.push"><code>Vec::push</code></a> call), it is worth using <a href="https://doc.rust-lang.org/std/macro.eprintln.html"><code>eprintln!</code></a> to print the vector length
at that site and then doing some post-processing (e.g. with <a href="https://github.com/nnethercote/counts/"><code>counts</code></a>) to
determine the length distribution. For example, you might have many short
vectors, or you might have a smaller number of very long vectors, and the best
way to optimize the allocation site will vary accordingly.</p>
<h3><a class="header" href="#short-vecs" id="short-vecs">Short <code>Vec</code>s</a></h3>
<p>If you have many short vectors, you can use the <code>SmallVec</code> type from the
<a href="https://crates.io/crates/smallvec"><code>smallvec</code></a> crate. <code>SmallVec&lt;[T; N]&gt;</code> is a drop-in replacement for <code>Vec</code> that
can store <code>N</code> elements within the <code>SmallVec</code> itself, and then switches to a
heap allocation if the number of elements exceeds that. (Note also that
<code>vec![]</code> literals must be replaced with <code>smallvec![]</code> literals.)
<a href="https://github.com/rust-lang/rust/pull/50565/commits/78262e700dc6a7b57e376742f344e80115d2d3f2"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/55383/commits/526dc1421b48e3ee8357d58d997e7a0f4bb26915"><strong>Example 2</strong></a>.</p>
<p><code>SmallVec</code> reliably reduces the allocation rate when used appropriately, but
its use does not guarantee improved performance. It is slightly slower than
<code>Vec</code> for normal operations because it must always check if the elements are
heap-allocated or not. Also, If <code>N</code> is high or <code>T</code> is large, then the
<code>SmallVec&lt;[T; N]&gt;</code> itself can be larger than <code>Vec&lt;T&gt;</code>, and copying of
<code>SmallVec</code> values will be slower. As always, benchmarking is required to
confirm that an optimization is effective.</p>
<p>If you have many short vectors <em>and</em> you precisely know their maximum length,
<code>ArrayVec</code> from the <a href="https://crates.io/crates/arrayvec"><code>arrayvec</code></a> crate is a better choice than <code>SmallVec</code>. It
does not require the fallback to heap allocation, which makes it a little
faster.
<a href="https://github.com/rust-lang/rust/pull/74310/commits/c492ca40a288d8a85353ba112c4d38fe87ef453e"><strong>Example</strong></a>.</p>
<h3><a class="header" href="#longer-vecs" id="longer-vecs">Longer <code>Vec</code>s</a></h3>
<p>If you know the minimum or exact size of a vector, you can reserve a specific
capacity with <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.with_capacity"><code>Vec::with_capacity</code></a>, <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.reserve"><code>Vec::reserve</code></a>, or
<a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.reserve_exact"><code>Vec::reserve_exact</code></a>. For example, if you know a vector will grow to have at
least 20 elements, these functions can immediately provide a vector with a
capacity of at least 20 using a single allocation, whereas pushing the items
one at a time would result in four allocations (for capacities of 4, 8, 16, and
32).
<a href="https://github.com/rust-lang/rust/pull/77990/commits/a7f2bb634308a5f05f2af716482b67ba43701681"><strong>Example</strong></a>.</p>
<p>If you know the maximum length of a vector, the above functions also let you
not allocate excess space unnecessary. Similarly, <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.shrink_to_fit"><code>Vec::shrink_to_fit</code></a> can be
used to minimize wasted space, but note that it may cause a reallocation.</p>
<h2><a class="header" href="#string" id="string"><code>String</code></a></h2>
<p>A <a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a> contains heap-allocated bytes. The representation and operation of
<code>String</code> is very similar to a <code>Vec&lt;u8&gt;</code>. Many <code>Vec</code> methods relating to growth
and capacity have equivalents for <code>String</code>, such as
<a href="https://doc.rust-lang.org/std/string/struct.String.html#method.with_capacity"><code>String::with_capacity</code></a>.</p>
<p>The <code>SmallString</code> type from the <a href="https://crates.io/crates/smallstr"><code>smallstr</code></a> crate is similar to the <code>SmallVec</code>
type.</p>
<p>Note that the <code>format!</code> macro produces a <code>String</code>, which means it performs an
allocation. If you can avoid a <code>format!</code> call by using a string literal, that
will avoid this allocation.
<a href="https://github.com/rust-lang/rust/pull/55905/commits/c6862992d947331cd6556f765f6efbde0a709cf9"><strong>Example</strong></a>.</p>
<h2><a class="header" href="#hash-tables" id="hash-tables">Hash tables</a></h2>
<p><a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html"><code>HashSet</code></a> and <a href="https://doc.rust-lang.org/std/collections/struct.HashMap.html"><code>HashMap</code></a> are hash tables. Their representation and
operations are similar to those of <code>Vec</code>, in terms of allocations: they have
a single contiguous heap allocation, holding keys and values, which is
reallocated as necessary as the table grows. Many <code>Vec</code> methods relating to
growth and capacity have equivalents for <code>HashSet</code>/<code>HashMap</code>, such as
<a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.with_capacity"><code>HashSet::with_capacity</code></a>.</p>
<h2><a class="header" href="#cow" id="cow"><code>Cow</code></a></h2>
<p>Sometimes you have some borrowed data, such as a <code>&amp;str</code>, that is mostly
read-only but occasionally needs to be modified. Cloning the data every time
would be wasteful. Instead you can use “clone-on-write” semantics via the
<a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code>Cow</code></a> type, which can represent both borrowed and owned data.</p>
<p>Typically, when starting with a borrowed value <code>x</code> you wrap it in a <code>Cow</code> with
<code>Cow::Borrowed(x)</code>. Because <code>Cow</code> implements <a href="https://doc.rust-lang.org/std/ops/trait.Deref.html"><code>Deref</code></a>, you can call
non-mutating methods directly on the data it encloses. If mutation is desired,
<a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html#method.to_mut"><code>Cow::to_mut</code></a> will obtain a mutable reference to an owned value, cloning if
necessary.</p>
<p><code>Cow</code> can be fiddly to get working, but it is often worth the effort.
<a href="https://github.com/rust-lang/rust/pull/37064/commits/b043e11de2eb2c60f7bfec5e15960f537b229e20"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50855/commits/ad471452ba6fbbf91ad566dc4bdf1033a7281811"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/56336/commits/787959c20d062d396b97a5566e0a766d963af022"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/68848/commits/67da45f5084f98eeb20cc6022d68788510dc832a"><strong>Example 4</strong></a>.</p>
<h2><a class="header" href="#clone" id="clone"><code>clone</code></a></h2>
<p>Calling <a href="https://doc.rust-lang.org/std/clone/trait.Clone.html#tymethod.clone"><code>clone</code></a> on a value that contains heap allocated memory typically
involves additional allocations. For example, calling <code>clone</code> on a non-empty
<code>Vec</code> requires a new allocation for the elements (but note that the capacity of
the new <code>Vec</code> might not be the same as the capacity of the original <code>Vec</code>). The
exception is <code>Rc</code>/<code>Arc</code>, where a <code>clone</code> call just increments the reference
count.</p>
<p><a href="https://doc.rust-lang.org/std/clone/trait.Clone.html#method.clone_from"><code>clone_from</code></a> is an alternative to <code>clone</code>. <code>a.clone_from(&amp;b)</code> is equivalent
to <code>a = b.clone()</code> but may avoid unnecessary allocations. For example, if you
want to clone one <code>Vec</code> over the top of an existing <code>Vec</code>, the existing <code>Vec</code>‘s
heap allocation will be reused if possible, as the following example shows.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut v1: Vec&lt;u32&gt; = Vec::with_capacity(99);
let v2: Vec&lt;u32&gt; = vec![1, 2, 3];
v1.clone_from(&amp;v2); // v1's allocation is reused
assert_eq!(v1.capacity(), 99);
<span class="boring">}
</span></code></pre></pre>
<p>Although <code>clone</code> usually causes allocations, it is a reasonable thing to use in
many circumstances and can often make code simpler. Use profiling data to see
which <code>clone</code> calls are hot and worth taking the effort to avoid.</p>
<p>Sometimes Rust code ends up containing unnecessary <code>clone</code> calls, due to (a)
programmer error, or (b) changes in the code that render previously-necessary
<code>clone</code> calls unnecessary. If you see a hot <code>clone</code> call that does not seem
necessary, sometimes it can simply be removed.
<a href="https://github.com/rust-lang/rust/pull/37318/commits/e382267cfb9133ef12d59b66a2935ee45b546a61"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/37705/commits/11c1126688bab32f76dbe1a973906c7586da143f"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64302/commits/36b37e22de92b584b9cf4464ed1d4ad317b798be"><strong>Example 3</strong></a>.</p>
<h2><a class="header" href="#to_owned" id="to_owned"><code>to_owned</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/borrow/trait.ToOwned.html#tymethod.to_owned"><code>ToOwned::to_owned</code></a> is implemented for many common types. It creates owned
data from borrowed data, usually by cloning, and therefore often causes heap
allocations. For example, it can be used to create a <code>String</code> from a <code>&amp;str</code>.</p>
<p>Sometimes <code>to_owned</code> calls can be avoided by storing a reference to borrowed
data in a struct rather than an owned copy. This requires lifetime annotations
on the struct, complicating the code, and should only be done when profiling
and benchmarking shows that it is worthwhile.
<a href="https://github.com/rust-lang/rust/pull/50855/commits/6872377357dbbf373cfd2aae352cb74cfcc66f34"><strong>Example</strong></a>.</p>
<h2><a class="header" href="#reusing-collections" id="reusing-collections">Reusing Collections</a></h2>
<p>Sometimes you need to build up a collection such as a <code>Vec</code> in stages. It is
usually better to do this by modifying a single <code>Vec</code> than by building multiple
<code>Vec</code>s and then combining them.</p>
<p>For example, if you have a function <code>do_stuff</code> that produces a <code>Vec</code> that might
be called multiple times:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn do_stuff(x: u32, y: u32) -&gt; Vec&lt;u32&gt; {
    vec![x, y]
}
<span class="boring">}
</span></code></pre></pre>
<p>It might be better to instead modify a passed-in <code>Vec</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn do_stuff(x: u32, y: u32, vec: &amp;mut Vec&lt;u32&gt;) {
    vec.push(x);
    vec.push(y);
}
<span class="boring">}
</span></code></pre></pre>
<p>Sometimes it is worth keeping around a “workhorse” collection that can be
reused. For example, if a <code>Vec</code> is needed for each iteration of a loop, you
could declare the <code>Vec</code> outside the loop, use it within the loop body, and then
call <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.clear"><code>clear</code></a> at the end of the loop body (to empty the <code>Vec</code> without affecting
its capacity). This avoids allocations at the cost of obscuring the fact that
each iteration’s usage of the <code>Vec</code> is unrelated to the others.
<a href="https://github.com/rust-lang/rust/pull/77990/commits/45faeb43aecdc98c9e3f2b24edf2ecc71f39d323"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/51870/commits/b0c78120e3ecae5f4043781f7a3f79e2277293e7"><strong>Example 2</strong></a>.</p>
<p>Similarly, it is sometimes worth keeping a “workhorse” collection within a
struct, to be reused in one or more methods that are called repeatedly.</p>
<h2><a class="header" href="#using-an-alternative-allocator" id="using-an-alternative-allocator">Using an Alternative Allocator</a></h2>
<p>Another option for improving the performance of allocation-heavy Rust programs
is to replace the default (system) allocator with an alternative allocator. The
exact effect will depend on the individual program and the alternative
allocator chosen. It will also vary across platforms, because each platform’s
system allocator has its own strengths and weaknesses. The use of an
alternative allocator can also affect binary size.</p>
<p>One popular alternative allocator is <a href="https://github.com/jemalloc/jemalloc">jemalloc</a>, usable via the
<a href="https://crates.io/crates/jemallocator"><code>jemallocator</code></a> crate. To use it, add a dependency to your <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[dependencies]
jemallocator = &quot;0.3.2&quot;
</code></pre>
<p>Then add the following somewhere in your Rust code:</p>
<pre><code class="language-rust ignore">#[global_allocator]
static GLOBAL: jemallocator::Jemalloc = jemallocator::Jemalloc;
</code></pre>
<p>Another alternative allocator is <a href="https://github.com/microsoft/mimalloc">mimalloc</a>, usable via the <a href="https://docs.rs/mimalloc/0.1.22/mimalloc/"><code>mimalloc</code></a> crate.</p>
<h1><a class="header" href="#type-sizes" id="type-sizes">Type Sizes</a></h1>
<p>Shrinking oft-instantiated types can reduce peak memory usage, and also
improve performance by reducing memory traffic and cache pressure. (In
particular, note that types that are larger than 128 bytes are copied with
<code>memcpy</code> rather than inline code.)</p>
<p>The Rust compiler automatically sorts the fields in struct and enums to
minimize their sizes (unless the <code>#[repr(C)]</code> attribute is specified), so you
do not have to worry about field ordering. But there are still other ways to
minimize the size of hot types.</p>
<h2><a class="header" href="#measuring-type-sizes" id="measuring-type-sizes">Measuring Type Sizes</a></h2>
<p><a href="https://doc.rust-lang.org/std/mem/fn.size_of.html"><code>std::mem::size_of</code></a> gives the size of a type, in bytes, but often you want to
know the exact layout as well. For example, an enum might be surprisingly big,
which might be caused by one outsized variant.</p>
<p>The <code>-Zprint-type-sizes</code> option does exactly this. It isn’t enabled on release
versions of rustc, so you’ll need to use a nightly version of rustc. Here is
one possible invocation via Cargo:</p>
<pre><code class="language-text">RUSTFLAGS=-Zprint-type-sizes cargo +nightly build --release
</code></pre>
<p>And here is a possible invocation of rustc:</p>
<pre><code class="language-text">rustc +nightly -Zprint-type-sizes input.rs
</code></pre>
<p>It will print out details of the size, layout, and alignment of all types in
use. For example, for this type:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum E {
    A,
    B(i32),
    C(u64, u8, u64, u8),
    D(Vec&lt;u32&gt;),
}
<span class="boring">}
</span></code></pre></pre>
<p>it prints the following, plus information about a few built-in types.</p>
<pre><code class="language-text">print-type-size type: `E`: 32 bytes, alignment: 8 bytes
print-type-size     discriminant: 1 bytes
print-type-size     variant `D`: 31 bytes
print-type-size         padding: 7 bytes
print-type-size         field `.0`: 24 bytes, alignment: 8 bytes
print-type-size     variant `C`: 23 bytes
print-type-size         field `.1`: 1 bytes
print-type-size         field `.3`: 1 bytes
print-type-size         padding: 5 bytes
print-type-size         field `.0`: 8 bytes, alignment: 8 bytes
print-type-size         field `.2`: 8 bytes
print-type-size     variant `B`: 7 bytes
print-type-size         padding: 3 bytes
print-type-size         field `.0`: 4 bytes, alignment: 4 bytes
print-type-size     variant `A`: 0 bytes
</code></pre>
<p>The output shows the following.</p>
<ul>
<li>The size and alignment of the type.</li>
<li>For enums, the size of the discriminant.</li>
<li>For enums, the size of each variant (sorted from largest to smallest).</li>
<li>The size, alignment, and ordering of all fields. (Note that the compiler has
reordered variant <code>C</code>‘s fields to minimize the size of <code>E</code>.)</li>
<li>The size and location of all padding.</li>
</ul>
<p>Once you know the layout of a hot type, there are multiple ways to shrink it.</p>
<h2><a class="header" href="#smaller-enums" id="smaller-enums">Smaller Enums</a></h2>
<p>If an enum has an outsized variant, consider boxing one or more fields. For
example, you could change this type:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>type LargeType = [u8; 100];
enum A {
    X,
    Y(i32),
    Z(i32, LargeType),
}
<span class="boring">}
</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">type LargeType = [u8; 100];
</span>enum A {
    X,
    Y(i32),
    Z(Box&lt;(i32, LargeType)&gt;),
}
<span class="boring">}
</span></code></pre></pre>
<p>This reduces the type size at the cost of requiring an extra heap allocation
for the <code>A::Z</code> variant. This is more likely to be a net performance win if the
<code>A::Z</code> variant is relatively rare. The <code>Box</code> will also make <code>A::Z</code> slightly
less ergonomic to use, especially in <code>match</code> patterns.
<a href="https://github.com/rust-lang/rust/pull/37445/commits/a920e355ea837a950b484b5791051337cd371f5d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/55346/commits/38d9277a77e982e49df07725b62b21c423b6428e"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64302/commits/b972ac818c98373b6d045956b049dc34932c41be"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64374/commits/2fcd870711ce267c79408ec631f7eba8e0afcdf6"><strong>Example 4</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64394/commits/7f0637da5144c7435e88ea3805021882f077d50c"><strong>Example 5</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/71942/commits/27ae2f0d60d9201133e1f9ec7a04c05c8e55e665"><strong>Example 6</strong></a>.</p>
<h2><a class="header" href="#smaller-integers" id="smaller-integers">Smaller Integers</a></h2>
<p>It is often possible to shrink types by using smaller integer types. For
example, while it is most natural to use <code>usize</code> for indices, it is often
reasonable to stores indices as <code>u32</code>, <code>u16</code>, or even <code>u8</code>, and then coerce to
<code>usize</code> at use points.
<a href="https://github.com/rust-lang/rust/pull/49993/commits/4d34bfd00a57f8a8bdb60ec3f908c5d4256f8a9a"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50981/commits/8d0fad5d3832c6c1f14542ea0be038274e454524"><strong>Example 2</strong></a>.</p>
<h2><a class="header" href="#boxed-slices" id="boxed-slices">Boxed Slices</a></h2>
<p>Rust vectors contain three words: a length, a capacity, and a (possibly null)
pointer to some number of heap-allocated elements. If you have a vector that is
unlikely to be changed in the future, you can convert it to a <em>boxed slice</em>
with <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.into_boxed_slice"><code>Vec::into_boxed_slice</code></a>. A boxed slice contains only two words, a length
and a pointer. Any excess element capacity is dropped, which may cause a
reallocation.</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::mem::{size_of, size_of_val};
</span>let v: Vec&lt;u32&gt; = vec![1, 2, 3];
assert_eq!(size_of_val(&amp;v), 3 * size_of::&lt;usize&gt;());

let bs: Box&lt;[u32]&gt; = v.into_boxed_slice();
assert_eq!(size_of_val(&amp;bs), 2 * size_of::&lt;usize&gt;());
<span class="boring">}
</span></code></pre></pre>
<p>The boxed slice can be converted back to a vector with <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.into_vec"><code>slice::into_vec</code></a>
without any cloning or a reallocation.</p>
<h2><a class="header" href="#avoiding-regressions" id="avoiding-regressions">Avoiding Regressions</a></h2>
<p>If a type is hot enough that its size can affect performance, it is a good idea
to use a static assertion to ensure that it does not accidentally regress. The
following example uses a macro from the <a href="https://crates.io/crates/static_assertions"><code>static_assertions</code></a> crate.</p>
<pre><code class="language-rust ignore">  // This type is used a lot. Make sure it doesn't unintentionally get bigger.
  #[cfg(target_arch = &quot;x86_64&quot;)]
  static_assertions::assert_eq_size!(HotType, [u8; 64]);
</code></pre>
<p>The <code>cfg</code> attribute is important, because type sizes can vary on different
platforms. Restricting the assertion to <code>x86_64</code> (which is typically the most
widely-used platform) is likely to be good enough to prevent regressions in
practice.</p>
<h1><a class="header" href="#standard-library-types" id="standard-library-types">Standard Library Types</a></h1>
<p>It is worth reading through the documentation for common standard library
types—such as <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a>, <a href="https://doc.rust-lang.org/std/option/enum.Option.html"><code>Option</code></a>, <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a>, and <a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a>—to find interesting
functions that can sometimes be used to improve performance.</p>
<p>It is also worth knowing about high-performance alternatives to standard
library types, such as <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>Mutex</code></a>, <a href="https://doc.rust-lang.org/std/sync/struct.RwLock.html"><code>RwLock</code></a>, <a href="https://doc.rust-lang.org/std/sync/struct.Condvar.html"><code>Condvar</code></a>, and
<a href="https://doc.rust-lang.org/std/sync/struct.Once.html"><code>Once</code></a>.</p>
<h2><a class="header" href="#vec-1" id="vec-1"><code>Vec</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.remove"><code>Vec::remove</code></a> removes an element at a particular index and shifts all
subsequent elements one to the left, which makes it O(n). <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.swap_remove"><code>Vec::swap_remove</code></a>
replaces an element at a particular index with the final element, which does
not preserve ordering, but is O(1).</p>
<p><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.retain"><code>Vec::retain</code></a> efficiently removes multiple items from a <code>Vec</code>. There is an
equivalent method for other collection types such as <code>String</code>, <code>HashSet</code>, and
<code>HashMap</code>.</p>
<h2><a class="header" href="#option-and-result" id="option-and-result"><code>Option</code> and <code>Result</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or"><code>Option::ok_or</code></a> converts an <code>Option</code> into a <code>Result</code>, and is passed an <code>err</code>
parameter that is used if the <code>Option</code> value is <code>None</code>. <code>err</code> is computed
eagerly. If its computation is expensive, you should instead use
<a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or_else"><code>Option::ok_or_else</code></a>, which computes the error value lazily via a closure.
For example, this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn expensive() {}
</span><span class="boring">let o: Option&lt;u32&gt; = None;
</span>let r = o.ok_or(expensive()); // always evaluates `expensive()`
<span class="boring">}
</span></code></pre></pre>
<p>should be changed to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn expensive() {}
</span><span class="boring">let o: Option&lt;u32&gt; = None;
</span>let r = o.ok_or_else(|| expensive()); // evaluates `expensive()` only when needed
<span class="boring">}
</span></code></pre></pre>
<p><a href="https://github.com/rust-lang/rust/pull/50051/commits/5070dea2366104fb0b5c344ce7f2a5cf8af176b0"><strong>Example</strong></a>.</p>
<p>There are similar alternatives for <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.map_or"><code>Option::map_or</code></a>, <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.unwrap_or"><code>Option::unwrap_or</code></a>,
<a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.or"><code>Result::or</code></a>, <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.map_or"><code>Result::map_or</code></a>, and <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.unwrap_or"><code>Result::unwrap_or</code></a>.</p>
<h2><a class="header" href="#rc" id="rc"><code>Rc</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/rc/struct.Rc.html#method.make_mut"><code>Rc::make_mut</code></a> provides clone-on-write semantics for <code>Rc</code>. It makes a mutable
reference to an <code>Rc</code>. If the refcount is greater than one, it will <code>clone</code> the
inner value to ensure unique ownership; otherwise, it will modify the original
value. It is not needed often, but it can be extremely useful on occasion.
<a href="https://github.com/rust-lang/rust/pull/65198/commits/3832a634d3aa6a7c60448906e6656a22f7e35628"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65198/commits/75e0078a1703448a19e25eac85daaa5a4e6e68ac"><strong>Example 2</strong></a>.</p>
<h2><a class="header" href="#mutex-rwlock-condvar-and-once" id="mutex-rwlock-condvar-and-once"><code>Mutex</code>, <code>RwLock</code>, <code>Condvar</code>, and <code>Once</code></a></h2>
<p>The <a href="https://crates.io/crates/parking_lot"><code>parking_lot</code></a> crate provides alternative implementations of these
synchronization types that are smaller, faster, and more flexible than those in
the standard library. The APIs and semantics of the <code>parking_lot</code> types are
similar but not identical to those of the equivalent types in the standard
library.</p>
<h1><a class="header" href="#iterators" id="iterators">Iterators</a></h1>
<h2><a class="header" href="#collect" id="collect"><code>collect</code></a></h2>
<p><a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect"><code>Iterator::collect</code></a> converts an iterator into a collection such as <code>Vec</code>,
which typically requires an allocation. You should avoid calling <code>collect</code> if
the collection is then only iterated over again.</p>
<p>For this reason, it is often better to return an iterator type like <code>impl Iterator&lt;Item=T&gt;</code> from a function than a <code>Vec&lt;T&gt;</code>. Note that sometimes
additional lifetimes are required on these return types, as <a href="https://blog.katona.me/2019/12/29/Rust-Lifetimes-and-Iterators/">this post</a>
explains.
<a href="https://github.com/rust-lang/rust/pull/77990/commits/660d8a6550a126797aa66a417137e39a5639451b"><strong>Example</strong></a>.</p>
<p>Similarly, you can use <a href="https://doc.rust-lang.org/std/iter/trait.Extend.html#tymethod.extend"><code>extend</code></a> to extend an existing collection (such as a
<code>Vec</code>) with an iterator, rather than collecting the iterator into a <code>Vec</code> and
then using <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.append"><code>append</code></a>.</p>
<h2><a class="header" href="#chaining" id="chaining">Chaining</a></h2>
<p><a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.chain"><code>chain</code></a> can be very convenient, but it can also be slower than a single
iterator. It may be worth avoiding for hot iterators, if possible.
<a href="https://github.com/rust-lang/rust/pull/64801/commits/5ca99b750e455e9b5e13e83d0d7886486231e48a"><strong>Example</strong></a>.</p>
<p>Similarly, <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter_map"><code>filter_map</code></a> may be faster than using <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter"><code>filter</code></a> followed by
<a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map"><code>map</code></a>.</p>
<h1><a class="header" href="#io" id="io">I/O</a></h1>
<h2><a class="header" href="#locking" id="locking">Locking</a></h2>
<p>Rust’s <a href="https://doc.rust-lang.org/std/macro.print.html"><code>print!</code></a> and <a href="https://doc.rust-lang.org/std/macro.println.html"><code>println!</code></a> macros lock stdout on every call. If you
have repeated calls to these macros it may be better to lock stdout manually.</p>
<p>For example, change this code:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">let lines = vec![&quot;one&quot;, &quot;two&quot;, &quot;three&quot;];
</span>for line in lines {
    println!(&quot;{}&quot;, line);
}
<span class="boring">}
</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec![&quot;one&quot;, &quot;two&quot;, &quot;three&quot;];
</span>use std::io::Write;
let mut stdout = std::io::stdout();
let mut lock = stdout.lock();
for line in lines {
    writeln!(lock, &quot;{}&quot;, line)?;
}
// stdout is unlocked when `lock` is dropped
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<p>stdin and stderr can likewise be locked when doing repeated operations on them.</p>
<h2><a class="header" href="#buffering" id="buffering">Buffering</a></h2>
<p>Rust file I/O is unbuffered by default. If you have many small and repeated
read or write calls to a file or network socket, use <a href="https://doc.rust-lang.org/std/io/struct.BufReader.html"><code>BufReader</code></a> or
<a href="https://doc.rust-lang.org/std/io/struct.BufWriter.html"><code>BufWriter</code></a>. They maintain an in-memory buffer for input and output,
minimizing the number of system calls required.</p>
<p>For example, change this unbuffered output code:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec![&quot;one&quot;, &quot;two&quot;, &quot;three&quot;];
</span>use std::io::Write;
let mut out = std::fs::File::create(&quot;test.txt&quot;).unwrap();
for line in lines {
    writeln!(out, &quot;{}&quot;, line)?;
}
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<p>to this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn blah() -&gt; Result&lt;(), std::io::Error&gt; {
</span><span class="boring">let lines = vec![&quot;one&quot;, &quot;two&quot;, &quot;three&quot;];
</span>use std::io::{BufWriter, Write};
let mut out = std::fs::File::create(&quot;test.txt&quot;)?;
let mut buf = BufWriter::new(out);
for line in lines {
    writeln!(buf, &quot;{}&quot;, line)?;
}
buf.flush()?;
<span class="boring">Ok(())
</span><span class="boring">}
</span><span class="boring">}
</span></code></pre></pre>
<p>The explicit call to <a href="https://doc.rust-lang.org/std/io/trait.Write.html#tymethod.flush"><code>flush</code></a> is not strictly necessary, as flushing will
happen automatically when <code>buf</code> is dropped. However, in that case any error
that occurs on flushing will be ignored, whereas an explicit flush will make
that error explicit.</p>
<p>Note that buffering also works with stdout, so you might want to combine manual
locking <em>and</em> buffering when making many writes to stdout.</p>
<h2><a class="header" href="#reading-input-as-raw-bytes" id="reading-input-as-raw-bytes">Reading Input as Raw Bytes</a></h2>
<p>The built-in <a href="https://doc.rust-lang.org/std/string/struct.String.html">String</a> type uses UTF-8 internally, which adds a small, but
nonzero overhead caused by UTF-8 validation when you read input into it. If you
just want to process input bytes without worrying about UTF-8 (for example if
you handle ASCII text), you can use <a href="https://doc.rust-lang.org/std/io/trait.BufRead.html#method.read_until"><code>BufRead::read_until</code></a>.</p>
<p>There are also dedicated crates for reading <a href="https://github.com/Freaky/rust-linereader">byte-oriented lines of data</a>
and working with <a href="https://github.com/BurntSushi/bstr">byte strings</a>.</p>
<h1><a class="header" href="#logging-and-debugging" id="logging-and-debugging">Logging and Debugging</a></h1>
<p>Sometimes logging code or debugging code can slow down a program significantly.
Either the logging/debugging code itself is slow, or data collection code that
feeds into logging/debugging code is slow. Make sure that no unnecessary work
is done for logging/debugging purposes when logging/debugging is not enabled.
<a href="https://github.com/rust-lang/rust/pull/50246/commits/2e4f66a86f7baa5644d18bb2adc07a8cd1c7409d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/75133/commits/eeb4b83289e09956e0dda174047729ca87c709fe"><strong>Example 2</strong></a>.</p>
<p>Note that <a href="https://doc.rust-lang.org/std/macro.assert.html"><code>assert!</code></a> calls always run, but <a href="https://doc.rust-lang.org/std/macro.debug_assert.html"><code>debug_assert!</code></a> calls only run in
debug builds. If you have an assertion that is hot but is not necessary for
safety, consider making it a <code>debug_assert!</code>.
<a href="https://github.com/rust-lang/rust/pull/58210/commits/f7ed6e18160bc8fccf27a73c05f3935c9e8f672e"><strong>Example</strong></a>.</p>
<h1><a class="header" href="#wrapper-types" id="wrapper-types">Wrapper Types</a></h1>
<p>Rust has a variety of “wrapper” types, such as <a href="https://doc.rust-lang.org/std/cell/struct.RefCell.html"><code>RefCell</code></a> and <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>Mutex</code></a>, that
provide special behavior for values. Accessing these values can take a
non-trivial amount of time. If multiple such values are typically accessed
together, it may be better to put them within a single wrapper.</p>
<p>For example, a struct like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::sync::{Arc, Mutex};
</span>struct S {
    x: Arc&lt;Mutex&lt;u32&gt;&gt;,
    y: Arc&lt;Mutex&lt;u32&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>may be better represented like this:</p>
<pre><pre class="playground"><code class="language-rust edition2018">
<span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::sync::{Arc, Mutex};
</span>struct S {
    xy: Arc&lt;Mutex&lt;(u32, u32)&gt;&gt;,
}
<span class="boring">}
</span></code></pre></pre>
<p>Whether or not this helps performance will depend on the exact access patterns
of the values.
<a href="https://github.com/rust-lang/rust/pull/68694/commits/7426853ba255940b880f2e7f8026d60b94b42404"><strong>Example</strong></a>.</p>
<h1><a class="header" href="#machine-code" id="machine-code">Machine Code</a></h1>
<p>When you have a small piece of very hot code, it may be worth inspecting the
generated machine code to see if it has any inefficiencies. The <a href="https://godbolt.org/">Compiler
Explorer</a> website is an excellent resource when doing this.</p>
<p>Relatedly, the <a href="https://doc.rust-lang.org/core/arch/index.html"><code>core::arch</code></a> module provides access to architecture-specific
intrinsics, many of which relate to SIMD instructions.</p>
<h1><a class="header" href="#parallelism" id="parallelism">Parallelism</a></h1>
<p>Rust provides excellent support for safe parallel programming, which can lead
to large performance improvements. There are a variety of ways to introduce
parallelism into a program and the best way for any program will depend greatly
on its design. </p>
<p>An in-depth treatment of parallelism is beyond the scope of this book. If you
are interested in this topic, the documentation for the <a href="https://crates.io/crates/rayon"><code>rayon</code></a> and
<a href="https://crates.io/crates/crossbeam"><code>crossbeam</code></a> crates is a good place to start.</p>
<h1><a class="header" href="#general-tips" id="general-tips">General Tips</a></h1>
<p>The previous sections of this book have discussed Rust-specific techniques.
This section gives a brief overview of some general performance principles.</p>
<p>As long as the obvious pitfalls are avoided (e.g. <a href="build-configuration.html">using non-release builds</a>),
Rust generally has good performance. Especially if you are used to
dynamically-typed languages such as Python and Ruby.</p>
<p>Optimized code is often more complex and takes more effort to write than
unoptimized code. For this reason, it is only worth optimizing hot code.</p>
<p>The biggest performance improvement often come from changes to algorithms or
data structures, rather than low-level optimizations.
<a href="https://github.com/rust-lang/rust/pull/53383/commits/5745597e6195fe0591737f242d02350001b6c590"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/54318/commits/154be2c98cf348de080ce951df3f73649e8bb1a6"><strong>Example 2</strong></a>.</p>
<p>Writing code that works well with modern hardware is not always easy, but worth
striving for. For example, try to minimize cache misses and branch
mispredictions, where possible.</p>
<p>Most optimizations result in small speedups. Although no single small speedup
is noticeable, they really add up if you can do enough of them.</p>
<p>Different profilers have different strengths. It is good to use more than one.</p>
<p>When profiling indicates that a function is hot, there are two common ways to
speed things up: (a) make the function faster, and/or (b) avoid calling it as
much.</p>
<p>It is usually easier, and often as effective, to avoid silly slowdowns as it
is to introduce clever speedups.</p>
<p>Avoid computing things unless necessary. Lazy/on-demand computations are
often a win.
<a href="https://github.com/rust-lang/rust/pull/36592/commits/80a44779f7a211e075da9ed0ff2763afa00f43dc"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/50339/commits/989815d5670826078d9984a3515eeb68235a4687"><strong>Example 2</strong></a>.</p>
<p>Complex general cases can often be avoided by optimistically checking for
common special cases that are simpler.
<a href="https://github.com/rust-lang/rust/pull/68790/commits/d62b6f204733d255a3e943388ba99f14b053bf4a"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/53733/commits/130e55665f8c9f078dec67a3e92467853f400250"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65260/commits/59e41edcc15ed07de604c61876ea091900f73649"><strong>Example 3</strong></a>.
In particular, specially handling collections with 0, 1, or 2 elements is often
a win when small sizes dominate.
<a href="https://github.com/rust-lang/rust/pull/50932/commits/2ff632484cd8c2e3b123fbf52d9dd39b54a94505"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64627/commits/acf7d4dcdba4046917c61aab141c1dec25669ce9"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64949/commits/14192607d38f5501c75abea7a4a0e46349df5b5f"><strong>Example 3</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/64949/commits/d1a7bb36ad0a5932384eac03d3fb834efc0317e5"><strong>Example 4</strong></a>.</p>
<p>Similarly, when dealing with repetitive data, it is often possible to use a
simple form of data compression, by using a compact representation for common
values and then having a fallback to a secondary table for unusual values.
<a href="https://github.com/rust-lang/rust/pull/54420/commits/b2f25e3c38ff29eebe6c8ce69b8c69243faa440d"><strong>Example 1</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/59693/commits/fd7f605365b27bfdd3cd6763124e81bddd61dd28"><strong>Example 2</strong></a>,
<a href="https://github.com/rust-lang/rust/pull/65750/commits/eea6f23a0ed67fd8c6b8e1b02cda3628fee56b2f"><strong>Example 3</strong></a>.</p>
<p>When code deals with multiple cases, measure case frequencies and handle the
most common ones first.</p>
<p>When dealing with lookups that involve high locality, it can be a win to put a
small cache in front of a data structure.</p>
<p>Optimized code often has a non-obvious structure, which means that explanatory
comments are valuable, particularly those that reference profiling
measurements. A comment like “99% of the time this vector has 0 or 1 elements,
so handle those cases first” can be illuminating.</p>
<h1><a class="header" href="#compile-times" id="compile-times">Compile Times</a></h1>
<p>Although this book is primarily about improving the performance of Rust
programs, this section is about reducing the compile times of Rust programs,
because that is a related topic of interest to many people.</p>
<h2><a class="header" href="#linking" id="linking">Linking</a></h2>
<p>A big part of compile time is actually linking time, particularly when
rebuilding a program after a small change. On Linux and Windows you can select
lld as the linker, which is much faster than the default linker.</p>
<p>To specify lld from the command line, precede your build command with <code>RUSTFLAGS=&quot;-C link-arg=-fuse-ld=lld&quot;</code>.</p>
<p>To specify lld from a <code>Cargo.toml</code> file, add these lines:</p>
<pre><code class="language-text">[build]
rustflags = [&quot;-C&quot;, &quot;link-arg=-fuse-ld=lld&quot;]
</code></pre>
<p>Alternatively, add these lines:</p>
<pre><code class="language-text">[target.x86_64-unknown-linux-gnu]
linker = &quot;lld&quot;
</code></pre>
<p>You can use <a href="https://doc.rust-lang.org/cargo/reference/config.html">Cargo configuration files</a> to apply these configurations to more
than a single project.</p>
<p>lld is not fully supported for use with Rust, but it should work for most use
cases on Linux and Windows. There is a <a href="https://github.com/rust-lang/rust/issues/39915#issuecomment-618726211">GitHub Issue</a> tracking full support for
lld.</p>
<h2><a class="header" href="#incremental-compilation" id="incremental-compilation">Incremental Compilation</a></h2>
<p>The Rust compiler supports <a href="https://blog.rust-lang.org/2016/09/08/incremental.html">incremental compilation</a>, which avoids redoing
work when you recompile a crate. It can greatly speed up compilation, at the
cost of sometimes making the produced executable run a little more slowly. For
this reason, it is only enabled by default for debug builds. If you want to
enable it for release builds as well, add the following lines to the
<code>Cargo.toml</code> file.</p>
<pre><code class="language-toml">[profile.release]
incremental = true
</code></pre>
<p>See the <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#incremental">Cargo documentation</a> for more details about the <code>lto</code> setting, and
about enabling specific settings for different profiles.</p>
<h2><a class="header" href="#visualization" id="visualization">Visualization</a></h2>
<p>The Rust compiler has a feature that lets you visualize compilation of your
program. Build with this command:</p>
<pre><code class="language-text">cargo +nightly build -Ztimings
</code></pre>
<p>On completion it will print the name of an HTML file. Open that file in a web
browser. It contains a <a href="https://en.wikipedia.org/wiki/Gantt_chart">Gantt chart</a> that shows the dependencies between the
various crates in your program. This shows how much parallelism there is in
your crate graph, which can indicate if any large crates that serialize
compilation should be broken up.</p>
<h2><a class="header" href="#llvm-ir" id="llvm-ir">LLVM IR</a></h2>
<p>The Rust compiler uses <a href="https://llvm.org/">LLVM</a> for its back-end. LLVM’s execution can be a large
part of compile times, especially when the Rust compiler’s front end generates
a lot of <a href="https://en.wikipedia.org/wiki/Intermediate_representation">IR</a> which takes LLVM a long time to optimize.</p>
<p>These problems can be diagnosed with <a href="https://github.com/dtolnay/cargo-llvm-lines/"><code>cargo llvm-lines</code></a>, which shows which
Rust functions cause the most LLVM IR to be generated. Generic functions are
often the most important ones, because they can be instantiated dozens or even
hundreds of times in large programs.</p>
<p>If a generic function causes IR bloat, there are several ways to fix it. The
simplest is to just make the function smaller.
<a href="https://github.com/rust-lang/rust/pull/72166/commits/5a0ac0552e05c079f252482cfcdaab3c4b39d614"><strong>Example</strong></a>.</p>
<p>Another way is to move the non-generic parts of the function into a separate,
non-generic function, which will only be instantiated once. Whether or not this
is possible will depend on the details of the generic function. The non-generic
function can often be written as an inner function within the generic function,
to minimize its exposure to the rest of the code.
<a href="https://github.com/rust-lang/rust/pull/72013/commits/68b75033ad78d88872450a81745cacfc11e58178"><strong>Example</strong></a>.</p>
<p>Sometimes common utility functions like <a href="https://doc.rust-lang.org/std/option/enum.Option.html#method.map"><code>Option::map</code></a> and <a href="https://doc.rust-lang.org/std/result/enum.Result.html#method.map_err"><code>Result::map_err</code></a>
are instantiated many times. Replacing them with equivalent <code>match</code> expressions
can help compile times.</p>
<p>The effects of these sorts of changes on compile times will usually be small,
though occasionally they can be large.
<a href="https://github.com/servo/servo/issues/26585"><strong>Example</strong></a>.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
